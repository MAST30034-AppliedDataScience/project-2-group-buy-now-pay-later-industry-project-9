{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F, SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import DecisionTreeRegressor, RandomForestRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/08 21:50:37 WARN Utils: Your hostname, qinsitaodeMacBook-Air.local resolves to a loopback address: 127.0.0.1; using 100.92.15.134 instead (on interface en0)\n",
      "24/09/08 21:50:37 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/09/08 21:50:38 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# Create a Spark Session\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"consumer model\")\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True)\n",
    "    .config(\"spark.sql.parquet.cacheMetadata\", \"true\")\n",
    "    .config(\"spark.sql.session.timeZone\", \"Etc/UTC\")\n",
    "    .config(\"spark.driver.memory\", \"4g\")\n",
    "    .config(\"spark.execturo.memory\", \"2g\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "consumer_info = spark.read.parquet('../data/curated/consumer_info.parquet')\n",
    "transaction_records = spark.read.parquet('../data/curated/transaction_records.parquet')\n",
    "fraudulent_consumer_rate = spark.read.parquet('../data/curated/consumer_fraud_rate.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraudulent_consumer_with_info = consumer_info.join(fraudulent_consumer_rate, on=\"consumer_id\", how=\"inner\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average fraud probability in each postcode or state\n",
    "fraudulent_consumer_group_by_postcode = fraudulent_consumer_with_info.groupBy([\"postcode\"]).agg(F.avg(\"fraud_probability\").alias(\"average_fraud_prob_of_postcode\"))\n",
    "\n",
    "fraudulent_consumer_group_by_state = fraudulent_consumer_with_info.groupBy([\"state\"]).agg(F.avg(\"fraud_probability\").alias(\"average_fraud_prob_of_state\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get average fraud prob for each consumer\n",
    "average_fraudulent_consumer_rate = fraudulent_consumer_rate.groupBy(\"consumer_id\").agg(F.avg(\"fraud_probability\").alias(\"average_fraud_probability\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34864"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraudulent_consumer_rate.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20128"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of unique available fraudulent consumer\n",
    "average_fraudulent_consumer_rate.where(average_fraudulent_consumer_rate[\"average_fraud_probability\"]>0).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add consumer info to transaction records\n",
    "consumer_transaction_records = transaction_records.join(consumer_info, on=\"consumer_id\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/08 21:50:51 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>summary</th><th>dollar_value</th></tr>\n",
       "<tr><td>count</td><td>14195505</td></tr>\n",
       "<tr><td>mean</td><td>166.22895390891753</td></tr>\n",
       "<tr><td>stddev</td><td>517.8505602612809</td></tr>\n",
       "<tr><td>min</td><td>9.756658099412162E-8</td></tr>\n",
       "<tr><td>25%</td><td>26.128899475514228</td></tr>\n",
       "<tr><td>50%</td><td>62.22903376686649</td></tr>\n",
       "<tr><td>75%</td><td>150.41282294992547</td></tr>\n",
       "<tr><td>max</td><td>105193.88578925544</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-------+--------------------+\n",
       "|summary|        dollar_value|\n",
       "+-------+--------------------+\n",
       "|  count|            14195505|\n",
       "|   mean|  166.22895390891753|\n",
       "| stddev|   517.8505602612809|\n",
       "|    min|9.756658099412162E-8|\n",
       "|    25%|  26.128899475514228|\n",
       "|    50%|   62.22903376686649|\n",
       "|    75%|  150.41282294992547|\n",
       "|    max|  105193.88578925544|\n",
       "+-------+--------------------+"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# order has really high variance and value\n",
    "consumer_transaction_records.select(\"dollar_value\").summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analysis order value, consider the variance of order value and purchase frequency\n",
    "consumer_transaction_value_analysis =  consumer_transaction_records.groupBy(\"consumer_id\", \"state\", \"postcode\") \\\n",
    "                                        .agg(\n",
    "                                            F.avg(\"dollar_value\").alias(\"average_dollar_value\"),\n",
    "                                            F.min(\"dollar_value\").alias(\"min_dollar_value\"),\n",
    "                                            F.max(\"dollar_value\").alias(\"max_dollar_value\"),\n",
    "                                            F.count(\"dollar_value\").alias(\"transaction_count\"),\n",
    "                                            F.stddev(\"dollar_value\").alias(\"stddev_dollar_value\")\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data frame for modelling\n",
    "fraudulent_consumer_summary = average_fraudulent_consumer_rate \\\n",
    "    .join(consumer_transaction_value_analysis, on=\"consumer_id\", how=\"left\") \\\n",
    "    .join(fraudulent_consumer_group_by_postcode, on=\"postcode\", how=\"inner\") \\\n",
    "    .join(fraudulent_consumer_group_by_state, on=\"state\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 31:===================================================>     (9 + 1) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+-----------+-------------------------+--------------------+--------------------+------------------+-----------------+-------------------+------------------------------+---------------------------+\n",
      "|state|postcode|consumer_id|average_fraud_probability|average_dollar_value|    min_dollar_value|  max_dollar_value|transaction_count|stddev_dollar_value|average_fraud_prob_of_postcode|average_fraud_prob_of_state|\n",
      "+-----+--------+-----------+-------------------------+--------------------+--------------------+------------------+-----------------+-------------------+------------------------------+---------------------------+\n",
      "|  VIC|    3171|    1463154|       11.878266056831936|  187.92238278341324|0.002626295938134...| 9383.286300772766|              578|   601.940558510518|            11.643992863529116|         15.162124631050172|\n",
      "|   NT|     810|     240762|       10.591450552633916|  187.84754214087144|0.043988124325446215| 4405.580619592672|              591| 434.13251811389586|             10.85295043657941|          15.30870879989026|\n",
      "|   SA|    5271|     658654|        9.979160224757958|  167.08588312478656|  0.0515263765371069|3672.1862187126712|              590|  339.2081023263823|             16.08544883927027|         15.144591238945841|\n",
      "+-----+--------+-----------+-------------------------+--------------------+--------------------+------------------+-----------------+-------------------+------------------------------+---------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "fraudulent_consumer_summary.show(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Idea\n",
    "1. Time Frequency feature: https://ieeexplore.ieee.org/document/9399421/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of features to be used in the model\n",
    "features = [\n",
    "    \"average_dollar_value\", \"min_dollar_value\", \"max_dollar_value\", \n",
    "    \"transaction_count\", \"stddev_dollar_value\", \n",
    "    \"average_fraud_prob_of_postcode\", \"average_fraud_prob_of_state\"\n",
    "]\n",
    "\n",
    "# VectorAssembler to combine the features into a single vector\n",
    "assembler = VectorAssembler(inputCols=features, outputCol=\"features\")\n",
    "\n",
    "# Prepare the data\n",
    "data = assembler.transform(fraudulent_consumer_summary)\n",
    "\n",
    "train_data, test_data = data.randomSplit([0.8, 0.2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 45:===================================================>     (9 + 1) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------------------------------------------------------------+\n",
      "|features                                                                                                               |\n",
      "+-----------------------------------------------------------------------------------------------------------------------+\n",
      "|[141.6439163612012,0.19560924922318007,3565.3935880300764,594.0,253.34065624200048,17.56001508791763,14.40842251077964]|\n",
      "+-----------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "train_data.select(\"features\").show(1, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model regressor\n",
    "dt = DecisionTreeRegressor(labelCol=\"average_fraud_probability\", featuresCol=\"features\")\n",
    "\n",
    "rf = RandomForestRegressor(labelCol=\"average_fraud_probability\", featuresCol=\"features\")\n",
    "\n",
    "lr = LinearRegression(labelCol=\"average_fraud_probability\", featuresCol=\"features\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter grid\n",
    "dt_param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(dt.maxDepth, [3, 5, 7]) \\\n",
    "    .addGrid(dt.maxBins, [32, 64]) \\\n",
    "    .build()\n",
    "\n",
    "\n",
    "rf_param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(rf.numTrees, [10, 20]) \\\n",
    "    .addGrid(rf.maxDepth, [5, 7]) \\\n",
    "    .build()\n",
    "\n",
    "lr_param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(lr.regParam, [0.01, 0.1, 1.0]) \\\n",
    "    .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0]) \\\n",
    "    .build()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluator for regression models\n",
    "rmse_evaluator = RegressionEvaluator(\n",
    "    labelCol=\"average_fraud_probability\", \n",
    "    predictionCol=\"prediction\", \n",
    "    metricName=\"rmse\"  \n",
    ")\n",
    "\n",
    "r2_evaluator = RegressionEvaluator(\n",
    "    labelCol=\"average_fraud_probability\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"r2\" \n",
    ")\n",
    "\n",
    "# Cross-validation \n",
    "dt_cv = CrossValidator(\n",
    "    estimator=dt,\n",
    "    estimatorParamMaps=dt_param_grid,\n",
    "    evaluator=r2_evaluator,\n",
    "    numFolds=3\n",
    ")\n",
    "\n",
    "rf_cv = CrossValidator(\n",
    "    estimator=rf,\n",
    "    estimatorParamMaps=rf_param_grid,\n",
    "    evaluator=r2_evaluator,\n",
    "    numFolds=3\n",
    ")\n",
    "\n",
    "lr_cv = CrossValidator(\n",
    "    estimator=lr,\n",
    "    estimatorParamMaps=lr_param_grid,\n",
    "    evaluator=r2_evaluator,\n",
    "    numFolds=3  # Use 3 folds for cross-validation\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline \n",
    "dt_pipeline = Pipeline(stages=[dt_cv])\n",
    "\n",
    "rf_pipeline = Pipeline(stages=[rf_cv])\n",
    "\n",
    "lr_pipeline = Pipeline(stages=[lr_cv])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/08 22:15:19 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "24/09/08 22:15:19 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.VectorBLAS\n",
      "24/09/08 22:15:20 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.lapack.JNILAPACK\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Fit model\n",
    "\n",
    "# 6 mins\n",
    "#dt_model = dt_pipeline.fit(train_data)\n",
    "\n",
    "# 7 mins\n",
    "#rf_model = rf_pipeline.fit(train_data)\n",
    "\n",
    "# 4 mins\n",
    "lr_model = lr_pipeline.fit(train_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test data\n",
    "dt_predictions = dt_model.transform(test_data)\n",
    "rf_predictions = rf_model.transform(test_data)\n",
    "lr_predictions = lr_model.transform(test_data)\n",
    "\n",
    "\n",
    "dt_rmse = rmse_evaluator.evaluate(dt_predictions)\n",
    "dt_r2 = r2_evaluator.evaluate(dt_predictions)\n",
    "print(f\"Decision Tree RMSE: {dt_rmse}\")\n",
    "print(f\"Decision Tree R2: {dt_r2}\")           # RMSE: 6.93 R2: 0.45\n",
    "\n",
    "rf_rmse = rmse_evaluator.evaluate(rf_predictions)\n",
    "rf_r2 = r2_evaluator.evaluate(rf_predictions)\n",
    "print(f\"Random Forest RMSE: {rf_rmse}\")\n",
    "print(f\"Random Forest R2: {rf_r2}\")            # RMSE: 6.438397547267348 R2: 0.544903685111079\n",
    "\n",
    "lr_rmse = rmse_evaluator.evaluate(lr_predictions)\n",
    "lr_r2 = r2_evaluator.evaluate(lr_predictions)\n",
    "print(f\"Linear Regression RMSE: {lr_rmse}\")\n",
    "print(f\"Linear Regression R2: {lr_r2}\")  # RMSE: 7.547075797936904 R2: 0.400604603315338\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Best model hyperparameters`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_dt_model = dt_model.stages[-1].bestModel\n",
    "# print(f\"Best Decision Tree maxDepth: {best_dt_model._java_obj.getMaxDepth()}\")\n",
    "# print(f\"Best Decision Tree maxBins: {best_dt_model._java_obj.getMaxBins()}\")\n",
    "\n",
    "\n",
    "# best_rf_model = rf_model.stages[-1].bestModel\n",
    "# print(f\"Best Random Forest numTrees: {best_rf_model.getNumTrees}\")\n",
    "# print(f\"Best Random Forest maxDepth: {best_rf_model.getMaxDepth()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Feature importances__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = assembler.getInputCols()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Random forest and decision tree`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Feature  Importance\n",
      "2                max_dollar_value    0.400778\n",
      "5  average_fraud_prob_of_postcode    0.300999\n",
      "4             stddev_dollar_value    0.161478\n",
      "0            average_dollar_value    0.085434\n",
      "3               transaction_count    0.022092\n",
      "1                min_dollar_value    0.020101\n",
      "6     average_fraud_prob_of_state    0.009117\n",
      "\n",
      "                          Feature  Importance\n",
      "2                max_dollar_value    0.665321\n",
      "5  average_fraud_prob_of_postcode    0.330762\n",
      "0            average_dollar_value    0.002912\n",
      "3               transaction_count    0.001005\n",
      "1                min_dollar_value    0.000000\n",
      "4             stddev_dollar_value    0.000000\n",
      "6     average_fraud_prob_of_state    0.000000\n"
     ]
    }
   ],
   "source": [
    "best_rf_model = rf_model.stages[0].bestModel\n",
    "best_dt_model = dt_model.stages[0].bestModel\n",
    "\n",
    "dt_feature_importances = best_dt_model.featureImportances\n",
    "rf_feature_importances = best_rf_model.featureImportances\n",
    "\n",
    "rf_importances_df = pd.DataFrame({\n",
    "    \"Feature\": feature_names,\n",
    "    \"Importance\": rf_feature_importances.toArray()\n",
    "}).sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "dt_importances_df = pd.DataFrame({\n",
    "    \"Feature\": feature_names,\n",
    "    \"Importance\": dt_feature_importances.toArray()\n",
    "}).sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "print(rf_importances_df)\n",
    "print()\n",
    "print(dt_importances_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Linear regression`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Feature  Coefficient\n",
      "5  average_fraud_prob_of_postcode     0.665090\n",
      "6     average_fraud_prob_of_state     0.076113\n",
      "2                max_dollar_value     0.000872\n",
      "4             stddev_dollar_value     0.000000\n",
      "3               transaction_count    -0.012840\n",
      "0            average_dollar_value    -0.042757\n",
      "1                min_dollar_value    -0.043693\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get coefficients \n",
    "best_lr_model = lr_model.stages[0].bestModel\n",
    "coefficients = best_lr_model.coefficients\n",
    "# Get feature names from the VectorAssembler\n",
    "feature_importances = pd.DataFrame({\n",
    "    \"Feature\": feature_names,\n",
    "    \"Coefficient\": coefficients\n",
    "}).sort_values(by=\"Coefficient\", ascending=False)\n",
    "\n",
    "print(feature_importances)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
