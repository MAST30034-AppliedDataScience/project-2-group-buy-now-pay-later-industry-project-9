{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-16 21:42:48.682205: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-10-16 21:42:49.060292: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-10-16 21:42:49.062771: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-16 21:42:55.811716: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (2.2.2) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.sys.path.append(\"../\")\n",
    "from scripts.ranking_model_v2 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/16 21:43:16 WARN Utils: Your hostname, DESKTOP-H6V94HM resolves to a loopback address: 127.0.1.1; using 192.168.0.220 instead (on interface eth0)\n",
      "24/10/16 21:43:16 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/10/16 21:43:17 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "#  Create a Spark Session\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"Ranking Model\")\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True)\n",
    "    .config(\"spark.sql.parquet.cacheMetadata\", \"true\")\n",
    "    .config(\"spark.sql.session.timeZone\", \"Etc/UTC\")\n",
    "    .config(\"spark.driver.memory\", \"4g\")\n",
    "    .config(\"spark.executor.memory\", \"4g\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "sc = SparkContext.getOrCreate()\n",
    "sc.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ranking System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Reading transactions\n",
    "transactions = spark.read.parquet(f\"../data/curated/transactions.parquet\")\n",
    "transactions = transactions.withColumns(\n",
    "    {\"period\": F.date_format(F.col(\"order_datetime\"), \"yyyy-MM\")})\n",
    "transactions = transactions.drop(\"merchant_fp\", \"consumer_fp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading predicted fraud probabilities\n",
    "merchant_fp = spark.read.parquet(f\"../data/curated/predicted_merchant_fp.parquet\")\n",
    "consumer_fp = spark.read.parquet(f\"../data/curated/predicted_consumer_fp.parquet\")\n",
    "\n",
    "# Join with transaction data\n",
    "transactions_full = transactions.join(consumer_fp, on = ['consumer_id', 'order_datetime', 'order_id'], how = 'inner')\n",
    "transactions_full = transactions_full.join(merchant_fp, on = ['merchant_abn', 'order_datetime', 'order_id'], how = 'inner')\n",
    "# transactions_full.limit(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As there are many ways in ranking the top 100 merchants toi join the BNPL firm, we decided adopted the approach of an investor, consider each merchant as a \"projects\" and evaluating their value. To evluate the merchant's value, we will be using a modified version of **Discounted Cash Flow (DCF)** model where we substitute *cash flow* with *revenue*. The orignal DCF model has the below formula\n",
    "\n",
    "$$ \\text{DCF} = \\sum^{n}_{t=1}\\frac{CF_t}{(1+r)^t}$$\n",
    "\n",
    "where $t$ is the time period of cash flow and $r$ is the discount rate.\n",
    "\n",
    "The DCF model we based on is the one that use **Free Cash Flows (FCF)** from **Earning Before Interest and Tax (EBIT)**. EBIT are usually a percentage of sales revenue and in Corporate Financial Decision Making (FNCE20003), the formula for FCF is defined as\n",
    "\n",
    "$$ \\text{FCF} = \\text{EBIT}(1-t) + \\text{Depreciation} - \\text{Capital Expenditure} - \\Delta\\text{Working Capital}$$\n",
    "\n",
    "Since the BNPL charges merchant per transaction, this means that the firm is charging for a percentage of the sales revenue. Thus, the merchant doesn't pay the BNPL firm through EBIT or their FCF. This allows us to safely consider the percentage of revenue of the merchant as cash flows for the BNPL firm.\n",
    "\n",
    "We will calculate of the project's  DCF using revenues from September 2022, October 2022, and November 2022. The value of the DCF is then multipled by the take rate, which we will called **Expected Project Value (EPV)**. After that, we will assign weights or penalties to the DCF and pick the merchants with the highest DCF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate the data into desried format\n",
    "agg_transactions = transactions_full.groupBy(\"merchant_abn\", \"period\", \"take_rate\").agg(\n",
    "    F.count(F.col(\"order_id\")).alias(\"num_orders\"),\n",
    "    F.round(F.sum(\"dollar_value\"),2).alias('revenue'),\n",
    "    F.round(F.mean(F.col(\"dollar_value\")), 2).alias(\"revenue_per_order\"),\n",
    "    F.round(F.mean(F.col(\"merchant_fp\")), 2).alias(\"avg_merchant_fp\"),\n",
    "    F.round(F.mean(F.col(\"consumer_fp\")), 2).alias(\"avg_consumer_fp\")\n",
    ")\n",
    "\n",
    "agg_transactions = agg_transactions.orderBy([\"merchant_abn\", \"period\"], ascending = [False, True])\n",
    "\n",
    "# Partition the data based on merchant ABN and comput lag variables for each specific partition\n",
    "merchant_partition = Window.partitionBy(\"merchant_abn\").orderBy(\"period\")\n",
    "agg_transactions = agg_transactions.withColumns({\n",
    "    \"revenue_lag_1\": F.lag(\"revenue\", 1, None).over(merchant_partition),\n",
    "    \"revenue_lag_2\": F.lag(\"revenue\", 2, None).over(merchant_partition),\n",
    "    \"revenue_lag_3\": F.lag(\"revenue\", 3, None).over(merchant_partition),\n",
    "    \"num_order_lag_1\": F.lag(\"num_orders\", 1, None).over(merchant_partition),\n",
    "    \"num_order_lag_2\": F.lag(\"num_orders\", 2, None).over(merchant_partition),\n",
    "    \"expected_profit\": F.round(F.col(\"revenue\") * F.col(\"take_rate\")/100,2)\n",
    "    })\n",
    "agg_transactions = agg_transactions.withColumns({\n",
    "    \"revenue_growth\":\n",
    "        F.when(F.col(\"revenue_lag_1\").isNotNull(), F.round((F.col(\"revenue\") - F.col(\"revenue_lag_1\"))/F.col(\"revenue_lag_1\"), 2)).otherwise(None),\n",
    "    \"revenue_growth_lag_1\": F.when(F.col(\"revenue_lag_2\").isNotNull(), \n",
    "        F.round((F.col(\"revenue_lag_1\") - F.col(\"revenue_lag_2\"))/F.col(\"revenue_lag_2\"), 2)).otherwise(None),\n",
    "    \"revenue_growth_lag_2\": F.when(F.col(\"revenue_lag_3\").isNotNull(), \n",
    "        F.round((F.col(\"revenue_lag_2\") - F.col(\"revenue_lag_3\"))/F.col(\"revenue_lag_3\"), 2)).otherwise(None)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing different merchants' values using the DCF model is only reliable when all merchants have revenue in the timeline of interest i.e from May 2021 to August 2022, all merchants must have sales in each month. We noticed that there are some merchants with no revenue in some particular month. Thus, we decide to asume that the missing revenue in some moths of some merchants are totally due to the merchant's inability to make any sales and not because of data entry errors. We adopted the perspective that we want merchants that have consistent sales. We will only consider merchants with 15 months of revenue records, prior to the date of the last transaction entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 7:=====================================================>   (15 + 1) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of merchants with complete sales records: 3212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Create a dataframe that store the valid date range of the data\n",
    "months = pd.date_range(start=\"2021-06-01\", end=\"2022-08-31\", freq='MS').strftime('%Y-%m').tolist()\n",
    "months_df = spark.createDataFrame([(month,) for month in months], [\"period\"])\n",
    "\n",
    "# Join with the transactions dataframe\n",
    "transactions_correct_months = transactions.join(months_df, on= ['period'], how = 'right')\n",
    "\n",
    "# Get the list of merchants with complete sales records\n",
    "complete_merchants = transactions_correct_months.groupBy(\"merchant_abn\").agg(F.countDistinct(\"period\")\\\n",
    "                                                                             .alias(\"month_count\")).filter(F.col(\"month_count\") == len(months)).select(\"merchant_abn\")\n",
    "print(f\"Number of merchants with complete sales records: {complete_merchants.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Select the merchants with complete sales records from the aggregated sales \n",
    "# print(f\"Number of entries before removing merchants with missing sales records: {agg_transactions.count()}\")\n",
    "# agg_transactions = agg_transactions.join(complete_merchants, on='merchant_abn', how='inner')\n",
    "# agg_transactions = agg_transactions.filter(\"2021-06\" <= F.col(\"period\")).orderBy(['merchant_abn', 'period'],\n",
    "#                                                                                       ascending = [True, True])\n",
    "# print(f\"Number of entries after removing merchants with missing sales records: {agg_transactions.count()}\")\n",
    "\n",
    "# # Export the aggregated transactions to reduce the need to run this block again\n",
    "# agg_transactions.write.parquet(f\"../data/curated/agg_transactions.parquet\", mode = 'overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_transactions = spark.read.parquet(f\"../data/curated/agg_transactions.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_transactions_sub = agg_transactions.select(*['merchant_abn', 'period', 'revenue', 'revenue_lag_1', 'revenue_lag_2', 'revenue_lag_3',\n",
    "'revenue_growth_lag_1', 'revenue_growth_lag_2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Since the last month of sales record is August 2022, this means that we have to forecast the revenues of the next 3 months. We will try 2 different approaches for forecasting revenue of 3 periods into the future. The first approach is to use a simple LSTM to predict the revenue. Contrast to the machine learning nature of approach 1, the second approach will be simply to compute the average monthly revenue growth rate of the 15 months period and then assume that revenues after August 2022 will grow by the same amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for merchant in complete_merchants.rdd.flatMap(lambda x:x).collect():\n",
    "#     # Predict sales revenue 3 period for all valid merchants\n",
    "#     partition = agg_transactions_sub.filter(F.col(\"merchant_abn\") == merchant)\n",
    "    \n",
    "#     forecasted_revenue = forecast_revenue(partition)\n",
    "\n",
    "#     print(forecasted_revenue)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we run the above code multiple times, we will see that the forecasted revenues will change with each rerun. This is because the weights between the units are randomly intialise each time and Stochastic Gradient Descent isn't guaranteed to always find the local maximum and minimum. Thus, in order to train a neural network that minimise the mean squared error, we would have to fine-tune our model. The process would be feasible if we're doing for 8-10 merchants. However, our data contains more than 3000 merchants which would be computationally expensive. Thus, we will stick with the second approach that was mentioned previously.\n",
    "\n",
    "Let's aggregate our data and find the monthly average growth for each merchant. From there, we can compute the DCF for each of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>merchant_abn</th><th>period</th><th>take_rate</th><th>num_orders</th><th>revenue</th><th>revenue_per_order</th><th>avg_merchant_fp</th><th>avg_consumer_fp</th><th>revenue_lag_1</th><th>revenue_lag_2</th><th>revenue_lag_3</th><th>num_order_lag_1</th><th>num_order_lag_2</th><th>expected_profit</th><th>revenue_growth</th><th>revenue_growth_lag_1</th><th>revenue_growth_lag_2</th></tr>\n",
       "<tr><td>63937753588</td><td>2021-10</td><td>4.17</td><td>14</td><td>42480.29</td><td>3034.31</td><td>41.25</td><td>16.06</td><td>20691.97</td><td>41997.37</td><td>36180.46</td><td>8</td><td>12</td><td>1771.43</td><td>1.05</td><td>-0.51</td><td>0.16</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+------------+-------+---------+----------+--------+-----------------+---------------+---------------+-------------+-------------+-------------+---------------+---------------+---------------+--------------+--------------------+--------------------+\n",
       "|merchant_abn| period|take_rate|num_orders| revenue|revenue_per_order|avg_merchant_fp|avg_consumer_fp|revenue_lag_1|revenue_lag_2|revenue_lag_3|num_order_lag_1|num_order_lag_2|expected_profit|revenue_growth|revenue_growth_lag_1|revenue_growth_lag_2|\n",
       "+------------+-------+---------+----------+--------+-----------------+---------------+---------------+-------------+-------------+-------------+---------------+---------------+---------------+--------------+--------------------+--------------------+\n",
       "| 63937753588|2021-10|     4.17|        14|42480.29|          3034.31|          41.25|          16.06|     20691.97|     41997.37|     36180.46|              8|             12|        1771.43|          1.05|               -0.51|                0.16|\n",
       "+------------+-------+---------+----------+--------+-----------------+---------------+---------------+-------------+-------------+-------------+---------------+---------------+---------------+--------------+--------------------+--------------------+"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_transactions.limit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "merchant_avg_growth = agg_transactions.groupBy(\"merchant_abn\", ).agg(\n",
    "    F.mean(F.col('revenue_growth')).alias('avg_monthly_revenue_growth'),\n",
    "    F.mean(F.col(\"num_orders\")).alias(\"avg_num_orders\"),\n",
    "    F.mean(F.col(\"revenue_per_order\")).alias('avg_revenue_per_order'),\n",
    "    (F.stddev(F.col('revenue'))/F.mean(F.col('revenue'))).alias(\"coef_of_variation\"),\n",
    "    F.stddev(F.col('revenue_growth')).alias(\"std_reveune_growth\")\n",
    ")\n",
    "merchant_latest_revenue = agg_transactions.filter(F.col(\"period\") == '2022-08').select(\"merchant_abn\", \"revenue\", \"take_rate\")\n",
    "merchant_latest_revenue = merchant_latest_revenue.join(merchant_avg_growth, on ='merchant_abn', how = 'inner')\n",
    "merchant_latest_revenue = merchant_latest_revenue.withColumns({\n",
    "    \"forecasted_revenue_1\": F.col(\"revenue\") * (1 + F.col(\"avg_monthly_revenue_growth\")),\n",
    "    \"forecasted_revenue_2\": F.col(\"revenue\") * (1 + F.col(\"avg_monthly_revenue_growth\"))**2,\n",
    "    \"forecasted_revenue_3\": F.col(\"revenue\") * (1 + F.col(\"avg_monthly_revenue_growth\"))**3,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the Victoria State Government [website](https://djsir.vic.gov.au/about-us/overview/the-economic-assessment-information-portal/i-am-looking-for-guidance-on-particular-economic-assessment-processes,-methods-and-variables#:~:text=Department%20of%20Treasury%20and%20Finance,on%20the%20category%20of%20investment.), there is no single discount rate. As a general guideline, the discount rate is between 4% and 7%. We acknowledge that each merchant may have their own discount rates but it's quite extensive to give each and everyone of them an individual discount rate. Thus, we will use the mid point of the recommended range and apply it to all merchants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>merchant_abn</th><th>avg_monthly_revenue_growth</th><th>avg_num_orders</th><th>avg_revenue_per_order</th><th>coef_of_variation</th><th>std_reveune_growth</th><th>discounted_revenue_flow</th><th>expected_project_value</th></tr>\n",
       "<tr><td>73256306726</td><td>0.02066666666666667</td><td>269.1333333333333</td><td>284.46199999999993</td><td>0.20053707832195655</td><td>0.23998412645919096</td><td>191447.79571678603</td><td>9208.638973977408</td></tr>\n",
       "<tr><td>73841664453</td><td>0.06533333333333333</td><td>47.13333333333333</td><td>86.75933333333334</td><td>0.2788256236984031</td><td>0.26699027983020196</td><td>15736.800264718144</td><td>873.392414691857</td></tr>\n",
       "<tr><td>78916025936</td><td>3.8819999999999992</td><td>3.8</td><td>321.5033333333332</td><td>0.7532806819543889</td><td>12.823639554688496</td><td>291776.5269985978</td><td>1079.5731498948119</td></tr>\n",
       "<tr><td>83412691377</td><td>0.025333333333333333</td><td>727.1333333333333</td><td>34.932</td><td>0.16312759228803875</td><td>0.17307581603227556</td><td>77261.59325069639</td><td>2271.490841570474</td></tr>\n",
       "<tr><td>92202115241</td><td>0.09266666666666667</td><td>5.8</td><td>333.6026666666666</td><td>0.41587657752670437</td><td>0.6025833275711059</td><td>4417.673386814076</td><td>250.04031369367672</td></tr>\n",
       "<tr><td>96946925998</td><td>0.34</td><td>6.0</td><td>924.2446666666666</td><td>0.6041988901065665</td><td>1.3132565846561963</td><td>27450.551701676337</td><td>1644.2880469304125</td></tr>\n",
       "<tr><td>64185141673</td><td>1.1159999999999999</td><td>5.2</td><td>290.19066666666663</td><td>0.6354321269447655</td><td>2.478818266836034</td><td>15163.199259590589</td><td>874.9165972783769</td></tr>\n",
       "<tr><td>66610548417</td><td>0.092</td><td>10.8</td><td>936.6219999999998</td><td>0.2972128564236676</td><td>0.41068235900754246</td><td>39351.835035257325</td><td>2585.4155618164064</td></tr>\n",
       "<tr><td>71002398501</td><td>0.33999999999999997</td><td>6.466666666666667</td><td>326.126</td><td>0.4544716307485942</td><td>1.372630425757161</td><td>7819.599611378878</td><td>295.58086531012157</td></tr>\n",
       "<tr><td>72762528640</td><td>0.25133333333333335</td><td>3.6666666666666665</td><td>273.3106666666667</td><td>0.5389553454598275</td><td>0.9667387493650027</td><td>1296.750849223466</td><td>29.176894107527986</td></tr>\n",
       "<tr><td>87211363921</td><td>0.06000000000000001</td><td>35.13333333333333</td><td>55.967333333333336</td><td>0.3353069504218318</td><td>0.375347458078131</td><td>4872.837716257444</td><td>32.64801269892487</td></tr>\n",
       "<tr><td>68874243493</td><td>0.24133333333333332</td><td>14.266666666666667</td><td>3198.2326666666672</td><td>0.45992313698924436</td><td>0.9829682938257299</td><td>99133.61879431811</td><td>2498.1671936168163</td></tr>\n",
       "<tr><td>80421506936</td><td>0.04733333333333334</td><td>26.666666666666668</td><td>84.776</td><td>0.18529927722569514</td><td>0.215720277431766</td><td>7486.991294832171</td><td>381.8365560364407</td></tr>\n",
       "<tr><td>81583941068</td><td>0.022666666666666665</td><td>191.13333333333333</td><td>298.1940000000001</td><td>0.1870711541709492</td><td>0.20457156158548484</td><td>155520.77665641758</td><td>4727.831610355094</td></tr>\n",
       "<tr><td>86662713230</td><td>0.02533333333333333</td><td>1094.2666666666667</td><td>52.40200000000001</td><td>0.1853516272668784</td><td>0.1852745710200584</td><td>166307.1756759368</td><td>10660.289960827547</td></tr>\n",
       "<tr><td>90568944804</td><td>0.03666666666666667</td><td>541.6</td><td>901.3306666666667</td><td>0.18814575097036243</td><td>0.22843150479071922</td><td>1530233.3272726843</td><td>62739.56641818005</td></tr>\n",
       "<tr><td>98545158925</td><td>0.041999999999999996</td><td>257.73333333333335</td><td>40.972</td><td>0.18931001682279155</td><td>0.21294533168330854</td><td>28202.551190090388</td><td>600.7143403489252</td></tr>\n",
       "<tr><td>63937753588</td><td>0.16133333333333333</td><td>12.0</td><td>2977.2613333333334</td><td>0.3044827841360601</td><td>0.5310618294197641</td><td>135898.61419222382</td><td>5666.972211815733</td></tr>\n",
       "<tr><td>71305424518</td><td>0.05133333333333332</td><td>22.666666666666668</td><td>51.638000000000005</td><td>0.3090333290976863</td><td>0.35411593474185155</td><td>3016.85222147923</td><td>76.0246759812766</td></tr>\n",
       "<tr><td>71649111610</td><td>0.7346666666666664</td><td>8.266666666666667</td><td>289.3773333333333</td><td>0.6942064834299622</td><td>2.3842425172268826</td><td>28174.490597478878</td><td>1214.3205447513394</td></tr>\n",
       "</table>\n",
       "only showing top 20 rows\n"
      ],
      "text/plain": [
       "+------------+--------------------------+------------------+---------------------+-------------------+-------------------+-----------------------+----------------------+\n",
       "|merchant_abn|avg_monthly_revenue_growth|    avg_num_orders|avg_revenue_per_order|  coef_of_variation| std_reveune_growth|discounted_revenue_flow|expected_project_value|\n",
       "+------------+--------------------------+------------------+---------------------+-------------------+-------------------+-----------------------+----------------------+\n",
       "| 73256306726|       0.02066666666666667| 269.1333333333333|   284.46199999999993|0.20053707832195655|0.23998412645919096|     191447.79571678603|     9208.638973977408|\n",
       "| 73841664453|       0.06533333333333333| 47.13333333333333|    86.75933333333334| 0.2788256236984031|0.26699027983020196|     15736.800264718144|      873.392414691857|\n",
       "| 78916025936|        3.8819999999999992|               3.8|    321.5033333333332| 0.7532806819543889| 12.823639554688496|      291776.5269985978|    1079.5731498948119|\n",
       "| 83412691377|      0.025333333333333333| 727.1333333333333|               34.932|0.16312759228803875|0.17307581603227556|      77261.59325069639|     2271.490841570474|\n",
       "| 92202115241|       0.09266666666666667|               5.8|    333.6026666666666|0.41587657752670437| 0.6025833275711059|      4417.673386814076|    250.04031369367672|\n",
       "| 96946925998|                      0.34|               6.0|    924.2446666666666| 0.6041988901065665| 1.3132565846561963|     27450.551701676337|    1644.2880469304125|\n",
       "| 64185141673|        1.1159999999999999|               5.2|   290.19066666666663| 0.6354321269447655|  2.478818266836034|     15163.199259590589|     874.9165972783769|\n",
       "| 66610548417|                     0.092|              10.8|    936.6219999999998| 0.2972128564236676|0.41068235900754246|     39351.835035257325|    2585.4155618164064|\n",
       "| 71002398501|       0.33999999999999997| 6.466666666666667|              326.126| 0.4544716307485942|  1.372630425757161|      7819.599611378878|    295.58086531012157|\n",
       "| 72762528640|       0.25133333333333335|3.6666666666666665|    273.3106666666667| 0.5389553454598275| 0.9667387493650027|      1296.750849223466|    29.176894107527986|\n",
       "| 87211363921|       0.06000000000000001| 35.13333333333333|   55.967333333333336| 0.3353069504218318|  0.375347458078131|      4872.837716257444|     32.64801269892487|\n",
       "| 68874243493|       0.24133333333333332|14.266666666666667|   3198.2326666666672|0.45992313698924436| 0.9829682938257299|      99133.61879431811|    2498.1671936168163|\n",
       "| 80421506936|       0.04733333333333334|26.666666666666668|               84.776|0.18529927722569514|  0.215720277431766|      7486.991294832171|     381.8365560364407|\n",
       "| 81583941068|      0.022666666666666665|191.13333333333333|    298.1940000000001| 0.1870711541709492|0.20457156158548484|     155520.77665641758|     4727.831610355094|\n",
       "| 86662713230|       0.02533333333333333|1094.2666666666667|    52.40200000000001| 0.1853516272668784| 0.1852745710200584|      166307.1756759368|    10660.289960827547|\n",
       "| 90568944804|       0.03666666666666667|             541.6|    901.3306666666667|0.18814575097036243|0.22843150479071922|     1530233.3272726843|     62739.56641818005|\n",
       "| 98545158925|      0.041999999999999996|257.73333333333335|               40.972|0.18931001682279155|0.21294533168330854|     28202.551190090388|     600.7143403489252|\n",
       "| 63937753588|       0.16133333333333333|              12.0|   2977.2613333333334| 0.3044827841360601| 0.5310618294197641|     135898.61419222382|     5666.972211815733|\n",
       "| 71305424518|       0.05133333333333332|22.666666666666668|   51.638000000000005| 0.3090333290976863|0.35411593474185155|       3016.85222147923|      76.0246759812766|\n",
       "| 71649111610|        0.7346666666666664| 8.266666666666667|    289.3773333333333| 0.6942064834299622| 2.3842425172268826|     28174.490597478878|    1214.3205447513394|\n",
       "+------------+--------------------------+------------------+---------------------+-------------------+-------------------+-----------------------+----------------------+\n",
       "only showing top 20 rows"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discount_rate = 1.055\n",
    "\n",
    "merchant_latest_revenue = merchant_latest_revenue.withColumns(\n",
    "    {\"discounted_revenue_flow\": F.col(\"forecasted_revenue_1\")/discount_rate + F.col(\"forecasted_revenue_2\")/discount_rate**2 + F.col(\"forecasted_revenue_3\")/discount_rate**3,\n",
    "     \"expected_project_value\": F.col(\"discounted_revenue_flow\") * F.col('take_rate')/100}\n",
    "    )\n",
    "merchant_latest_revenue = merchant_latest_revenue.drop(\"forecasted_revenue_1\", \"forecasted_revenue_2\", \"forecasted_revenue_3\", \"revenue\", \"take_rate\")\n",
    "merchant_latest_revenue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also be using the predicted fraud probability for both merchants and consumer as part of our ranking system. We will assign our weights of choice, $\\alpha$ and $\\beta$ to the merchants and consumers' fraud probability, respectively, and sum them. We think that the merchant's fraud probability is more important to the BNPL firm as a merchant with a higher fraud probability with likely to commit scams, thus damaging the BNPL firm's reputation and customer will not shop from the firm anymore. Whereas for customer, it's easier to assess the risk of a customer not paying for the items. Thus, we decided the weight is going to be $\\alpha = 0.65$ and $\\beta = 0.35$. The formula for the combined fraud probability is:\n",
    "\n",
    "$$\\text{Combined Fraud Probability (CBF)} = \\alpha \\times \\text{Merchant's FP} + \\beta\\times\\text{Consumer's FP}$$\n",
    "\n",
    "We will use the combined fraud probability to get the fraud-adjusted DCF\n",
    "\n",
    "$$ \\text{Fraud-adjusted EPV} = (1 - \\text{CBF}) \\times \\text{EPV}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_fp = agg_transactions.withColumns({\n",
    "    \"total_merchant_fp\": F.col(\"avg_merchant_fp\") * F.col(\"num_orders\"),\n",
    "    \"total_consumer_fp\": F.col(\"avg_consumer_fp\") * F.col(\"num_orders\"),\n",
    "}).select(\"merchant_abn\", \"period\", \"num_orders\", \"total_merchant_fp\", \"total_consumer_fp\")\n",
    "\n",
    "avg_fp = avg_fp.groupBy(\"merchant_abn\").agg(\n",
    "    (F.sum(F.col(\"total_merchant_fp\"))/F.sum(F.col(\"num_orders\"))).alias(\"avg_merchant_fp\"),\n",
    "    (F.sum(F.col(\"total_consumer_fp\"))/F.sum(F.col(\"num_orders\"))).alias(\"avg_consumer_fp\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.65\n",
    "beta = 0.35\n",
    "\n",
    "avg_fp = avg_fp.withColumn(\"combined_fp\", alpha * F.col(\"avg_merchant_fp\") + beta * F.col('avg_consumer_fp'))\n",
    "merchant_ranking_metrics = merchant_latest_revenue.join(avg_fp, on='merchant_abn', how='inner')\n",
    "merchant_ranking_metrics = merchant_ranking_metrics.drop(\"avg_merchant_fp\",\"avg_consumer_fp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "merchant_ranking_metrics = merchant_ranking_metrics.withColumn(\n",
    "    \"risk_adjusted_epv\",\n",
    "    F.col(\"expected_project_value\") * (1 - F.col(\"combined_fp\")/100)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>merchant_abn</th><th>avg_monthly_revenue_growth</th><th>avg_num_orders</th><th>avg_revenue_per_order</th><th>coef_of_variation</th><th>std_reveune_growth</th><th>discounted_revenue_flow</th><th>expected_project_value</th><th>combined_fp</th><th>risk_adjusted_epv</th></tr>\n",
       "<tr><td>70344541271</td><td>51.08466666666667</td><td>4.866666666666666</td><td>1081.5886666666665</td><td>0.5737462225685777</td><td>195.37035923989032</td><td>7.229664594670486E8</td><td>4.128138483556847E7</td><td>42.42405479452055</td><td>2.3768147512990005E7</td></tr>\n",
       "<tr><td>71616292306</td><td>27.928666666666665</td><td>2.6666666666666665</td><td>210.442</td><td>0.730322688378949</td><td>106.90505098762485</td><td>5417787.616379169</td><td>177161.6550555988</td><td>39.5622125</td><td>107072.58461398579</td></tr>\n",
       "<tr><td>95276443363</td><td>15.658666666666665</td><td>3.6</td><td>296.6186666666666</td><td>0.6820969976318357</td><td>51.655349033856346</td><td>6601250.027970397</td><td>251507.6260656721</td><td>39.01125925925927</td><td>153391.33400438444</td></tr>\n",
       "<tr><td>75547072158</td><td>12.812666666666667</td><td>3.8666666666666667</td><td>284.17533333333336</td><td>0.7476836101265073</td><td>48.9629811281174</td><td>253224.4641329908</td><td>11445.745778811182</td><td>39.041500000000006</td><td>6977.154940576614</td></tr>\n",
       "<tr><td>12171241826</td><td>10.885333333333334</td><td>8.2</td><td>228.37266666666665</td><td>0.568344026863831</td><td>40.80740511697543</td><td>5073911.329712124</td><td>209552.5379171107</td><td>38.0224756097561</td><td>129875.47529795238</td></tr>\n",
       "<tr><td>33223110337</td><td>10.853333333333333</td><td>2.8</td><td>214.40200000000002</td><td>0.9092808051054941</td><td>38.67401336199554</td><td>463179.7602395222</td><td>21908.402659329404</td><td>38.604011904761904</td><td>13450.880288578708</td></tr>\n",
       "<tr><td>70783350473</td><td>10.031333333333333</td><td>3.066666666666667</td><td>576.6173333333334</td><td>0.5781118668358438</td><td>36.41120272401783</td><td>2314209.098268511</td><td>42812.86831796745</td><td>38.95503260869566</td><td>26135.101503985294</td></tr>\n",
       "<tr><td>52129470223</td><td>9.220000000000002</td><td>4.866666666666666</td><td>309.45399999999995</td><td>0.6017263523053834</td><td>33.47001707285407</td><td>3312653.5794925285</td><td>109317.56812325344</td><td>39.02289726027398</td><td>66658.68582708623</td></tr>\n",
       "<tr><td>33790986203</td><td>7.944</td><td>5.2</td><td>327.7420000000001</td><td>0.6609718021645656</td><td>27.62230615178351</td><td>2327647.7691004816</td><td>140589.9252536691</td><td>41.86257051282051</td><td>81735.3686604302</td></tr>\n",
       "<tr><td>51420872378</td><td>8.786666666666665</td><td>2.8</td><td>258.158</td><td>0.9624601796783046</td><td>23.669936829738464</td><td>30096.247715517915</td><td>990.1665498405393</td><td>38.90971428571428</td><td>604.8955743448707</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+------------+--------------------------+------------------+---------------------+------------------+------------------+-----------------------+----------------------+------------------+--------------------+\n",
       "|merchant_abn|avg_monthly_revenue_growth|    avg_num_orders|avg_revenue_per_order| coef_of_variation|std_reveune_growth|discounted_revenue_flow|expected_project_value|       combined_fp|   risk_adjusted_epv|\n",
       "+------------+--------------------------+------------------+---------------------+------------------+------------------+-----------------------+----------------------+------------------+--------------------+\n",
       "| 70344541271|         51.08466666666667| 4.866666666666666|   1081.5886666666665|0.5737462225685777|195.37035923989032|    7.229664594670486E8|   4.128138483556847E7| 42.42405479452055|2.3768147512990005E7|\n",
       "| 71616292306|        27.928666666666665|2.6666666666666665|              210.442| 0.730322688378949|106.90505098762485|      5417787.616379169|     177161.6550555988|        39.5622125|  107072.58461398579|\n",
       "| 95276443363|        15.658666666666665|               3.6|    296.6186666666666|0.6820969976318357|51.655349033856346|      6601250.027970397|     251507.6260656721| 39.01125925925927|  153391.33400438444|\n",
       "| 75547072158|        12.812666666666667|3.8666666666666667|   284.17533333333336|0.7476836101265073|  48.9629811281174|      253224.4641329908|    11445.745778811182|39.041500000000006|   6977.154940576614|\n",
       "| 12171241826|        10.885333333333334|               8.2|   228.37266666666665| 0.568344026863831| 40.80740511697543|      5073911.329712124|     209552.5379171107|  38.0224756097561|  129875.47529795238|\n",
       "| 33223110337|        10.853333333333333|               2.8|   214.40200000000002|0.9092808051054941| 38.67401336199554|      463179.7602395222|    21908.402659329404|38.604011904761904|  13450.880288578708|\n",
       "| 70783350473|        10.031333333333333| 3.066666666666667|    576.6173333333334|0.5781118668358438| 36.41120272401783|      2314209.098268511|     42812.86831796745| 38.95503260869566|  26135.101503985294|\n",
       "| 52129470223|         9.220000000000002| 4.866666666666666|   309.45399999999995|0.6017263523053834| 33.47001707285407|     3312653.5794925285|    109317.56812325344| 39.02289726027398|   66658.68582708623|\n",
       "| 33790986203|                     7.944|               5.2|    327.7420000000001|0.6609718021645656| 27.62230615178351|     2327647.7691004816|     140589.9252536691| 41.86257051282051|    81735.3686604302|\n",
       "| 51420872378|         8.786666666666665|               2.8|              258.158|0.9624601796783046|23.669936829738464|     30096.247715517915|     990.1665498405393| 38.90971428571428|   604.8955743448707|\n",
       "+------------+--------------------------+------------------+---------------------+------------------+------------------+-----------------------+----------------------+------------------+--------------------+"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merchant_ranking_metrics.orderBy(\"std_reveune_growth\", ascending = False).limit(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the table above, we can see that the merchant 1 has a risk-adjusted EPV of approximately $23 millions. This is due to their average monthly revenue growth rate is 5108% which is a massive growth. This is due to fact that this merchant has highly fluctuating monthly revenue growth rate which may affect the average monthly growth rate. Thus, it's important that we penalised merchant with high revenue growth standard deviation. We will use a modified Winsorizor method to remove any standard deviation of revenue growth that are outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the intial approach for removing  merchant with unstable revenue growth rate. Double click the cell to view\n",
    "<!-- The formula for calculating the weight is\n",
    "\n",
    "$$W_{\\text{Revenue growth}} = \\frac{1}{\\log (1+s^{\\text{r.g}}_i)} - \\frac{1}{2}$$\n",
    "\n",
    "where $s^{\\text{rev growth}}_i$ is the standard deviation of the merchant's revenue growth rate accross the 15 months period. -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "lower_bound = merchant_ranking_metrics.select(F.percentile(F.col(\"std_reveune_growth\"), 0.01)).first()[0]\n",
    "upper_bound = merchant_ranking_metrics.select(F.percentile(F.col(\"std_reveune_growth\"), 0.99)).first()[0]\n",
    "\n",
    "merchant_ranking_metrics = merchant_ranking_metrics.filter((lower_bound <= F.col(\"std_reveune_growth\")) & (F.col(\"std_reveune_growth\") <= upper_bound))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "growth_df = merchant_latest_revenue.select(\"merchant_abn\", \"avg_monthly_revenue_growth\").toPandas()\n",
    "\n",
    "# Scatter plot: Merchants vs Growth Rate\n",
    "df_sorted = growth_df.sort_values(by='avg_monthly_revenue_growth', ascending=False)\n",
    "top_5 = df_sorted.head(5)\n",
    "\n",
    "plt.style.use('seaborn-white')\n",
    "plt.figure(facecolor='#FDFDFD')\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.scatter(growth_df['merchant_abn'], growth_df['avg_monthly_revenue_growth'] * 100, color='#4C91D4', label='All Merchants') # Plot all merchants\n",
    "plt.scatter(top_5['merchant_abn'], top_5['avg_monthly_revenue_growth']* 100, color='#FF6F61', label='Top 5 Merchants') # Highlight the top 5 merchants with red color\n",
    "plt.axhline(30, color='#AD505E', linestyle='dashed', linewidth=2)\n",
    "plt.text(10, 30, \"30%\", color='#AD505E',  fontweight= 'bold')\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "\n",
    "for i, row in top_5.iterrows():\n",
    "    plt.annotate(f\"{round(row['avg_monthly_revenue_growth'] *100,2)}\", (row['merchant_abn'], row['avg_monthly_revenue_growth']*100), textcoords=\"offset points\", xytext=(0,5), ha='center')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xticks([])\n",
    "plt.title(\"Average Monthly Reveune Growth\", fontweight = 'bold', fontsize=14, pad=20)\n",
    "plt.ylabel(\"Growth rate (%)\", fontsize = 12)\n",
    "# plt.savefig(f\"../plots/growth_rate\", transparent = True)\n",
    "plt.savefig(f\"../plots/growth_rate_v2\", transparent = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>merchant_abn</th><th>avg_monthly_revenue_growth</th><th>avg_num_orders</th><th>avg_revenue_per_order</th><th>coef_of_variation</th><th>std_reveune_growth</th><th>discounted_revenue_flow</th><th>expected_project_value</th><th>combined_fp</th><th>risk_adjusted_epv</th></tr>\n",
       "<tr><td>97884414539</td><td>1.6406666666666667</td><td>3.0</td><td>9981.536666666665</td><td>0.7347099651497621</td><td>4.043104300033871</td><td>1895396.73499406</td><td>129266.05732659489</td><td>44.049511111111116</td><td>72324.99104162121</td></tr>\n",
       "<tr><td>48534649627</td><td>0.025333333333333336</td><td>3335.4666666666667</td><td>143.09733333333332</td><td>0.17851904439502903</td><td>0.1612392484418581</td><td>1400750.4061942906</td><td>93009.82697130089</td><td>30.673439088983052</td><td>64480.51434849038</td></tr>\n",
       "<tr><td>86578477987</td><td>0.026000000000000002</td><td>13805.266666666666</td><td>35.028</td><td>0.17180320536602955</td><td>0.1635236985883086</td><td>1426866.798267028</td><td>91747.5351285699</td><td>30.291424461195973</td><td>63955.89983008991</td></tr>\n",
       "<tr><td>32361057556</td><td>0.025333333333333333</td><td>4341.933333333333</td><td>109.82733333333334</td><td>0.1775619949607971</td><td>0.17058163804494092</td><td>1380419.1374607098</td><td>91245.70498615292</td><td>30.4234067389335</td><td>63485.65302640829</td></tr>\n",
       "<tr><td>45629217853</td><td>0.027333333333333334</td><td>11255.333333333334</td><td>37.83866666666667</td><td>0.18717135892602974</td><td>0.17826411651842677</td><td>1265784.8255556792</td><td>88351.78082378641</td><td>30.81994237694723</td><td>61121.81288488873</td></tr>\n",
       "<tr><td>79827781481</td><td>0.028666666666666667</td><td>241.2</td><td>2036.1873333333338</td><td>0.1758887478875903</td><td>0.18814381530652352</td><td>1417110.0615200887</td><td>96646.90619567005</td><td>38.2490462962963</td><td>59680.386300950144</td></tr>\n",
       "<tr><td>21439773999</td><td>0.024666666666666667</td><td>6118.266666666666</td><td>78.28</td><td>0.17513345558089158</td><td>0.16422400497346243</td><td>1387461.9684095625</td><td>84635.1800729833</td><td>30.246255208446836</td><td>59036.20751198023</td></tr>\n",
       "<tr><td>96680767841</td><td>0.029333333333333333</td><td>1582.3333333333333</td><td>315.58133333333336</td><td>0.1762583893366516</td><td>0.18997994881666053</td><td>1468326.4819790302</td><td>86778.09508496069</td><td>32.35259734569201</td><td>58703.12739786161</td></tr>\n",
       "<tr><td>38700038932</td><td>0.02266666666666666</td><td>365.26666666666665</td><td>1337.1320000000003</td><td>0.17855375493793263</td><td>0.17878425412717286</td><td>1418536.365320908</td><td>89509.64465174929</td><td>34.81062803431283</td><td>58350.77519719366</td></tr>\n",
       "<tr><td>64403598239</td><td>0.025333333333333333</td><td>5752.2</td><td>78.12666666666668</td><td>0.17188020953378486</td><td>0.1548209411207793</td><td>1323501.879621348</td><td>83512.96860410707</td><td>30.271728173568377</td><td>58232.14975859427</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+------------+--------------------------+------------------+---------------------+-------------------+-------------------+-----------------------+----------------------+------------------+------------------+\n",
       "|merchant_abn|avg_monthly_revenue_growth|    avg_num_orders|avg_revenue_per_order|  coef_of_variation| std_reveune_growth|discounted_revenue_flow|expected_project_value|       combined_fp| risk_adjusted_epv|\n",
       "+------------+--------------------------+------------------+---------------------+-------------------+-------------------+-----------------------+----------------------+------------------+------------------+\n",
       "| 97884414539|        1.6406666666666667|               3.0|    9981.536666666665| 0.7347099651497621|  4.043104300033871|       1895396.73499406|    129266.05732659489|44.049511111111116| 72324.99104162121|\n",
       "| 48534649627|      0.025333333333333336|3335.4666666666667|   143.09733333333332|0.17851904439502903| 0.1612392484418581|     1400750.4061942906|     93009.82697130089|30.673439088983052| 64480.51434849038|\n",
       "| 86578477987|      0.026000000000000002|13805.266666666666|               35.028|0.17180320536602955| 0.1635236985883086|      1426866.798267028|      91747.5351285699|30.291424461195973| 63955.89983008991|\n",
       "| 32361057556|      0.025333333333333333| 4341.933333333333|   109.82733333333334| 0.1775619949607971|0.17058163804494092|     1380419.1374607098|     91245.70498615292|  30.4234067389335| 63485.65302640829|\n",
       "| 45629217853|      0.027333333333333334|11255.333333333334|    37.83866666666667|0.18717135892602974|0.17826411651842677|     1265784.8255556792|     88351.78082378641| 30.81994237694723| 61121.81288488873|\n",
       "| 79827781481|      0.028666666666666667|             241.2|   2036.1873333333338| 0.1758887478875903|0.18814381530652352|     1417110.0615200887|     96646.90619567005|  38.2490462962963|59680.386300950144|\n",
       "| 21439773999|      0.024666666666666667| 6118.266666666666|                78.28|0.17513345558089158|0.16422400497346243|     1387461.9684095625|      84635.1800729833|30.246255208446836| 59036.20751198023|\n",
       "| 96680767841|      0.029333333333333333|1582.3333333333333|   315.58133333333336| 0.1762583893366516|0.18997994881666053|     1468326.4819790302|     86778.09508496069| 32.35259734569201| 58703.12739786161|\n",
       "| 38700038932|       0.02266666666666666|365.26666666666665|   1337.1320000000003|0.17855375493793263|0.17878425412717286|      1418536.365320908|     89509.64465174929| 34.81062803431283| 58350.77519719366|\n",
       "| 64403598239|      0.025333333333333333|            5752.2|    78.12666666666668|0.17188020953378486| 0.1548209411207793|      1323501.879621348|     83512.96860410707|30.271728173568377| 58232.14975859427|\n",
       "+------------+--------------------------+------------------+---------------------+-------------------+-------------------+-----------------------+----------------------+------------------+------------------+"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merchant_ranking_metrics.orderBy(\"risk_adjusted_epv\", ascending = False).limit(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are also some merchant with a very few amount of orders per month. From the BNPL perspective, we would want merchants with a decent amount of order volume per month as more volume would likely result in more revenue for BNPL firm. We also found that a low average monthly order volume also lead to unstable growth rate, thus, led to unrealistic forecasted revenues. Thus, we need to create a weight that penalises merchant with low order volume. The weight is compute using a Sigmoid function\n",
    "\n",
    "$$ W_{\\text{num orders}} = \\frac{1}{1 + e^{-(\\bar{x_i} - \\bar{x_{.}})}}$$\n",
    "\n",
    "where $\\bar{x_i}$ is the average number of order of merchant $i$ and $\\bar{x_.}$ is the average number of order of all merchants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "avg_order_vol = merchant_latest_revenue.select(\"merchant_abn\", \"avg_num_orders\").toPandas()\n",
    "\n",
    "log_mean_order_volume = np.log(np.mean(avg_order_vol['avg_num_orders']))\n",
    "plt.figure(facecolor='#FDFDFD')\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.axvline(np.exp(log_mean_order_volume), color='#AD505E', linestyle='dashed', linewidth=2)\n",
    "_, bins, _ = plt.hist(avg_order_vol['avg_num_orders'], bins=20, color=\"#50AD9F\", edgecolor=\"black\", log=True, alpha=0.5)\n",
    "plt.text(np.exp(log_mean_order_volume + 1.4) , 50, f'{np.exp(log_mean_order_volume):.2f}', color='#AD505E',  fontweight= 'bold',\n",
    "         horizontalalignment='center', verticalalignment='bottom')\n",
    "plt.xticks(bins, rotation=45)\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "# plt.savefig(f\"../plots/order_volume\", transparent = True)\n",
    "plt.title(\"Histogram of Order Volume\", fontweight='bold', size=14, pad=20)\n",
    "plt.ylabel(\"Log Frequency\", fontsize = 12)\n",
    "plt.xlabel(\"Order Volume\", fontsize=12)\n",
    "plt.savefig(f\"../plots/order_volume_v2\", transparent = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "212.6747613117476"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(avg_order_vol['avg_num_orders'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.359764056546743"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_mean_order_volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "212.6747613117476"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute average monthly order volume of all merchants\n",
    "mean_num_orders = agg_transactions.agg(F.mean(\"num_orders\")).collect()[0][0]\n",
    "mean_num_orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>merchant_abn</th><th>avg_monthly_revenue_growth</th><th>avg_num_orders</th><th>avg_revenue_per_order</th><th>coef_of_variation</th><th>std_reveune_growth</th><th>discounted_revenue_flow</th><th>expected_project_value</th><th>combined_fp</th><th>risk_adjusted_epv</th></tr>\n",
       "<tr><td>48534649627</td><td>0.025333333333333336</td><td>3335.4666666666667</td><td>143.09733333333332</td><td>0.17851904439502903</td><td>0.1612392484418581</td><td>1400750.4061942906</td><td>93009.82697130089</td><td>30.673439088983052</td><td>64480.51434849038</td></tr>\n",
       "<tr><td>86578477987</td><td>0.026000000000000002</td><td>13805.266666666666</td><td>35.028</td><td>0.17180320536602955</td><td>0.1635236985883086</td><td>1426866.798267028</td><td>91747.5351285699</td><td>30.291424461195973</td><td>63955.89983008991</td></tr>\n",
       "<tr><td>32361057556</td><td>0.025333333333333333</td><td>4341.933333333333</td><td>109.82733333333334</td><td>0.1775619949607971</td><td>0.17058163804494092</td><td>1380419.1374607098</td><td>91245.70498615292</td><td>30.4234067389335</td><td>63485.65302640829</td></tr>\n",
       "<tr><td>45629217853</td><td>0.027333333333333334</td><td>11255.333333333334</td><td>37.83866666666667</td><td>0.18717135892602974</td><td>0.17826411651842677</td><td>1265784.8255556792</td><td>88351.78082378641</td><td>30.81994237694723</td><td>61121.81288488873</td></tr>\n",
       "<tr><td>79827781481</td><td>0.028666666666666667</td><td>241.2</td><td>2036.1873333333338</td><td>0.1758887478875903</td><td>0.18814381530652352</td><td>1417110.0615200887</td><td>96646.90619567005</td><td>38.2490462962963</td><td>59680.38630092573</td></tr>\n",
       "<tr><td>21439773999</td><td>0.024666666666666667</td><td>6118.266666666666</td><td>78.28</td><td>0.17513345558089158</td><td>0.16422400497346243</td><td>1387461.9684095625</td><td>84635.1800729833</td><td>30.246255208446836</td><td>59036.20751198023</td></tr>\n",
       "<tr><td>96680767841</td><td>0.029333333333333333</td><td>1582.3333333333333</td><td>315.58133333333336</td><td>0.1762583893366516</td><td>0.18997994881666053</td><td>1468326.4819790302</td><td>86778.09508496069</td><td>32.35259734569201</td><td>58703.12739786161</td></tr>\n",
       "<tr><td>38700038932</td><td>0.02266666666666666</td><td>365.26666666666665</td><td>1337.1320000000003</td><td>0.17855375493793263</td><td>0.17878425412717286</td><td>1418536.365320908</td><td>89509.64465174929</td><td>34.81062803431283</td><td>58350.77519719366</td></tr>\n",
       "<tr><td>64403598239</td><td>0.025333333333333333</td><td>5752.2</td><td>78.12666666666668</td><td>0.17188020953378486</td><td>0.1548209411207793</td><td>1323501.879621348</td><td>83512.96860410707</td><td>30.271728173568377</td><td>58232.14975859427</td></tr>\n",
       "<tr><td>89726005175</td><td>0.026</td><td>10937.533333333333</td><td>41.28066666666666</td><td>0.17785400363988527</td><td>0.1696551123392901</td><td>1346359.9274887978</td><td>80916.23164207675</td><td>30.303525237256423</td><td>56395.76096538315</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+------------+--------------------------+------------------+---------------------+-------------------+-------------------+-----------------------+----------------------+------------------+-----------------+\n",
       "|merchant_abn|avg_monthly_revenue_growth|    avg_num_orders|avg_revenue_per_order|  coef_of_variation| std_reveune_growth|discounted_revenue_flow|expected_project_value|       combined_fp|risk_adjusted_epv|\n",
       "+------------+--------------------------+------------------+---------------------+-------------------+-------------------+-----------------------+----------------------+------------------+-----------------+\n",
       "| 48534649627|      0.025333333333333336|3335.4666666666667|   143.09733333333332|0.17851904439502903| 0.1612392484418581|     1400750.4061942906|     93009.82697130089|30.673439088983052|64480.51434849038|\n",
       "| 86578477987|      0.026000000000000002|13805.266666666666|               35.028|0.17180320536602955| 0.1635236985883086|      1426866.798267028|      91747.5351285699|30.291424461195973|63955.89983008991|\n",
       "| 32361057556|      0.025333333333333333| 4341.933333333333|   109.82733333333334| 0.1775619949607971|0.17058163804494092|     1380419.1374607098|     91245.70498615292|  30.4234067389335|63485.65302640829|\n",
       "| 45629217853|      0.027333333333333334|11255.333333333334|    37.83866666666667|0.18717135892602974|0.17826411651842677|     1265784.8255556792|     88351.78082378641| 30.81994237694723|61121.81288488873|\n",
       "| 79827781481|      0.028666666666666667|             241.2|   2036.1873333333338| 0.1758887478875903|0.18814381530652352|     1417110.0615200887|     96646.90619567005|  38.2490462962963|59680.38630092573|\n",
       "| 21439773999|      0.024666666666666667| 6118.266666666666|                78.28|0.17513345558089158|0.16422400497346243|     1387461.9684095625|      84635.1800729833|30.246255208446836|59036.20751198023|\n",
       "| 96680767841|      0.029333333333333333|1582.3333333333333|   315.58133333333336| 0.1762583893366516|0.18997994881666053|     1468326.4819790302|     86778.09508496069| 32.35259734569201|58703.12739786161|\n",
       "| 38700038932|       0.02266666666666666|365.26666666666665|   1337.1320000000003|0.17855375493793263|0.17878425412717286|      1418536.365320908|     89509.64465174929| 34.81062803431283|58350.77519719366|\n",
       "| 64403598239|      0.025333333333333333|            5752.2|    78.12666666666668|0.17188020953378486| 0.1548209411207793|      1323501.879621348|     83512.96860410707|30.271728173568377|58232.14975859427|\n",
       "| 89726005175|                     0.026|10937.533333333333|    41.28066666666666|0.17785400363988527| 0.1696551123392901|     1346359.9274887978|     80916.23164207675|30.303525237256423|56395.76096538315|\n",
       "+------------+--------------------------+------------------+---------------------+-------------------+-------------------+-----------------------+----------------------+------------------+-----------------+"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merchant_ranking_metrics = merchant_ranking_metrics.withColumn(\"risk_adjusted_epv\", F.col(\"risk_adjusted_epv\") * (1/(1 + F.exp(-F.col(\"avg_num_orders\"))*np.exp(mean_num_orders))))\n",
    "merchant_ranking_metrics.orderBy(\"risk_adjusted_epv\", ascending = False).limit(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **coefficient of variation** is a ratio between the standard deviation and the mean, measuring the relative stability which help us compare merchants with different average revenue. Thus, we will create a weight that favors merchant with higher stability. The weight is calculate as\n",
    "\n",
    "$$W_{\\text{CV}} = \\frac{1}{1 + CV}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>merchant_abn</th><th>avg_monthly_revenue_growth</th><th>avg_num_orders</th><th>avg_revenue_per_order</th><th>coef_of_variation</th><th>std_reveune_growth</th><th>discounted_revenue_flow</th><th>expected_project_value</th><th>combined_fp</th><th>risk_adjusted_epv</th></tr>\n",
       "<tr><td>48534649627</td><td>0.025333333333333336</td><td>3335.4666666666667</td><td>143.09733333333332</td><td>0.17851904439502903</td><td>0.1612392484418581</td><td>1400750.4061942906</td><td>93009.82697130089</td><td>30.673439088983052</td><td>54713.17129337545</td></tr>\n",
       "<tr><td>86578477987</td><td>0.026000000000000002</td><td>13805.266666666666</td><td>35.028</td><td>0.17180320536602955</td><td>0.1635236985883086</td><td>1426866.798267028</td><td>91747.5351285699</td><td>30.291424461195973</td><td>54579.04496012397</td></tr>\n",
       "<tr><td>32361057556</td><td>0.025333333333333333</td><td>4341.933333333333</td><td>109.82733333333334</td><td>0.1775619949607971</td><td>0.17058163804494092</td><td>1380419.1374607098</td><td>91245.70498615292</td><td>30.4234067389335</td><td>53912.79040771167</td></tr>\n",
       "<tr><td>45629217853</td><td>0.027333333333333334</td><td>11255.333333333334</td><td>37.83866666666667</td><td>0.18717135892602974</td><td>0.17826411651842677</td><td>1265784.8255556792</td><td>88351.78082378641</td><td>30.81994237694723</td><td>51485.24888621164</td></tr>\n",
       "<tr><td>79827781481</td><td>0.028666666666666667</td><td>241.2</td><td>2036.1873333333338</td><td>0.1758887478875903</td><td>0.18814381530652352</td><td>1417110.0615200887</td><td>96646.90619567005</td><td>38.2490462962963</td><td>50753.42918974075</td></tr>\n",
       "<tr><td>21439773999</td><td>0.024666666666666667</td><td>6118.266666666666</td><td>78.28</td><td>0.17513345558089158</td><td>0.16422400497346243</td><td>1387461.9684095625</td><td>84635.1800729833</td><td>30.246255208446836</td><td>50237.87488272766</td></tr>\n",
       "<tr><td>96680767841</td><td>0.029333333333333333</td><td>1582.3333333333333</td><td>315.58133333333336</td><td>0.1762583893366516</td><td>0.18997994881666053</td><td>1468326.4819790302</td><td>86778.09508496069</td><td>32.35259734569201</td><td>49906.659905709246</td></tr>\n",
       "<tr><td>64403598239</td><td>0.025333333333333333</td><td>5752.2</td><td>78.12666666666668</td><td>0.17188020953378486</td><td>0.1548209411207793</td><td>1323501.879621348</td><td>83512.96860410707</td><td>30.271728173568377</td><td>49691.21355992612</td></tr>\n",
       "<tr><td>38700038932</td><td>0.02266666666666666</td><td>365.26666666666665</td><td>1337.1320000000003</td><td>0.17855375493793263</td><td>0.17878425412717286</td><td>1418536.365320908</td><td>89509.64465174929</td><td>34.81062803431283</td><td>49510.49110209373</td></tr>\n",
       "<tr><td>89726005175</td><td>0.026</td><td>10937.533333333333</td><td>41.28066666666666</td><td>0.17785400363988527</td><td>0.1696551123392901</td><td>1346359.9274887978</td><td>80916.23164207675</td><td>30.303525237256423</td><td>47880.09446935283</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+------------+--------------------------+------------------+---------------------+-------------------+-------------------+-----------------------+----------------------+------------------+------------------+\n",
       "|merchant_abn|avg_monthly_revenue_growth|    avg_num_orders|avg_revenue_per_order|  coef_of_variation| std_reveune_growth|discounted_revenue_flow|expected_project_value|       combined_fp| risk_adjusted_epv|\n",
       "+------------+--------------------------+------------------+---------------------+-------------------+-------------------+-----------------------+----------------------+------------------+------------------+\n",
       "| 48534649627|      0.025333333333333336|3335.4666666666667|   143.09733333333332|0.17851904439502903| 0.1612392484418581|     1400750.4061942906|     93009.82697130089|30.673439088983052| 54713.17129337545|\n",
       "| 86578477987|      0.026000000000000002|13805.266666666666|               35.028|0.17180320536602955| 0.1635236985883086|      1426866.798267028|      91747.5351285699|30.291424461195973| 54579.04496012397|\n",
       "| 32361057556|      0.025333333333333333| 4341.933333333333|   109.82733333333334| 0.1775619949607971|0.17058163804494092|     1380419.1374607098|     91245.70498615292|  30.4234067389335| 53912.79040771167|\n",
       "| 45629217853|      0.027333333333333334|11255.333333333334|    37.83866666666667|0.18717135892602974|0.17826411651842677|     1265784.8255556792|     88351.78082378641| 30.81994237694723| 51485.24888621164|\n",
       "| 79827781481|      0.028666666666666667|             241.2|   2036.1873333333338| 0.1758887478875903|0.18814381530652352|     1417110.0615200887|     96646.90619567005|  38.2490462962963| 50753.42918974075|\n",
       "| 21439773999|      0.024666666666666667| 6118.266666666666|                78.28|0.17513345558089158|0.16422400497346243|     1387461.9684095625|      84635.1800729833|30.246255208446836| 50237.87488272766|\n",
       "| 96680767841|      0.029333333333333333|1582.3333333333333|   315.58133333333336| 0.1762583893366516|0.18997994881666053|     1468326.4819790302|     86778.09508496069| 32.35259734569201|49906.659905709246|\n",
       "| 64403598239|      0.025333333333333333|            5752.2|    78.12666666666668|0.17188020953378486| 0.1548209411207793|      1323501.879621348|     83512.96860410707|30.271728173568377| 49691.21355992612|\n",
       "| 38700038932|       0.02266666666666666|365.26666666666665|   1337.1320000000003|0.17855375493793263|0.17878425412717286|      1418536.365320908|     89509.64465174929| 34.81062803431283| 49510.49110209373|\n",
       "| 89726005175|                     0.026|10937.533333333333|    41.28066666666666|0.17785400363988527| 0.1696551123392901|     1346359.9274887978|     80916.23164207675|30.303525237256423| 47880.09446935283|\n",
       "+------------+--------------------------+------------------+---------------------+-------------------+-------------------+-----------------------+----------------------+------------------+------------------+"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merchant_ranking_metrics = merchant_ranking_metrics.withColumn(\"risk_adjusted_epv\", F.col(\"risk_adjusted_epv\") * (1/(1 + F.col(\"coef_of_variation\") )))\n",
    "merchant_ranking_metrics.orderBy(\"risk_adjusted_epv\", ascending = False).limit(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have found the adjusted EPV that accounts for different factor, we can now merge the merchants to their respective segments and will select top 20 merchants from each segnment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------------------+--------------------------------------+-------------------------------------------------+\n",
      "|merchant_abn|risk_adjusted_epv     |name                                  |segments                                         |\n",
      "+------------+----------------------+--------------------------------------+-------------------------------------------------+\n",
      "|73256306726 |5106.3445582384       |Id LLP                                |Fashion, Personal Accessories, Health, and Beauty|\n",
      "|73841664453 |5.079036435468569E-70 |Lacinia At LLP                        |Books, Media, Arts, Crafts, and Hobbies          |\n",
      "|83412691377 |1405.0444371658846    |Suspendisse Sagittis Nullam Associates|Fashion, Personal Accessories, Health, and Beauty|\n",
      "|92202115241 |1.4102977797408417E-88|Fames Ac Turpis Limited               |Books, Media, Arts, Crafts, and Hobbies          |\n",
      "|96946925998 |1.0739640028656378E-87|Nisi Cum Corporation                  |Books, Media, Arts, Crafts, and Hobbies          |\n",
      "|64185141673 |2.3941758416049687E-88|Maecenas Corp.                        |Books, Media, Arts, Crafts, and Hobbies          |\n",
      "|66610548417 |2.4996015505912874E-85|Nulla Inc.                            |Vehicles, Repairs, and Miscellaneous Services    |\n",
      "|71002398501 |3.3941808635930086E-88|Ipsum Phasellus Corp.                 |Fashion, Personal Accessories, Health, and Beauty|\n",
      "|72762528640 |1.9403629120087297E-90|Sit Amet Risus Associates             |Vehicles, Repairs, and Miscellaneous Services    |\n",
      "|87211363921 |1.0379429906229265E-76|Mauris Non PC                         |Books, Media, Arts, Crafts, and Hobbies          |\n",
      "+------------+----------------------+--------------------------------------+-------------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Reading in the segmented merchants\n",
    "segments = spark.read.parquet(f\"../data/curated/segmented_merchants_info.parquet/\")\n",
    "segments = segments.select(\"name\", \"merchant_abn\", \"segments\")\n",
    "\n",
    "complete_ranking = merchant_ranking_metrics.select(\"merchant_abn\", \"risk_adjusted_epv\")\n",
    "\n",
    "# Merge ranking with segments\n",
    "complete_ranking = complete_ranking.join(segments, on = 'merchant_abn', how='inner')\n",
    "complete_ranking.show(10, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "grouped_segments = complete_ranking.groupBy(\"segments\").agg(F.count(\"merchant_abn\").alias('num_merchants')).orderBy(\"num_merchants\", ascending = False)\n",
    "grouped_segments_pd = grouped_segments.toPandas()\n",
    "colours = [\"#f7b03e\", \"#4c91d4\", \"#a265a8\", \"#27ae60\" ,\"#cb4760\"]\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.pie(grouped_segments_pd['num_merchants'], colors=colours, wedgeprops=dict(width=0.5), startangle=-40, explode= [0.05]*5, labels=grouped_segments_pd['segments'])\n",
    "plt.savefig(f\"../plots/donut_chart_segments\", transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "total_value_segments = complete_ranking.groupBy(\"segments\").agg(F.sum(\"risk_adjusted_epv\").alias(\"total_epv\")).orderBy(\"total_epv\", ascending=False)\n",
    "total_value_segments_pd = total_value_segments.toPandas()\n",
    "\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "plt.bar(total_value_segments_pd['segments'], total_value_segments_pd['total_epv'], color = colours, edgecolor = 'black')\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "plt.xticks([])\n",
    "plt.yticks(size=14)\n",
    "plt.savefig(f'../plots/total_revenue_segments', transparent = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>segments</th>\n",
       "      <th>total_epv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Books, Media, Arts, Crafts, and Hobbies</td>\n",
       "      <td>1.419670e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Computers, Electronics, and Office Supplies</td>\n",
       "      <td>9.237914e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Vehicles, Repairs, and Miscellaneous Services</td>\n",
       "      <td>8.031290e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fashion, Personal Accessories, Health, and Beauty</td>\n",
       "      <td>7.351826e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Home, Garden, and Furnishings</td>\n",
       "      <td>6.485205e+05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            segments     total_epv\n",
       "0            Books, Media, Arts, Crafts, and Hobbies  1.419670e+06\n",
       "1        Computers, Electronics, and Office Supplies  9.237914e+05\n",
       "2      Vehicles, Repairs, and Miscellaneous Services  8.031290e+05\n",
       "3  Fashion, Personal Accessories, Health, and Beauty  7.351826e+05\n",
       "4                      Home, Garden, and Furnishings  6.485205e+05"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/07 21:13:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:13:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:13:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:13:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:13:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:13:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:13:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:13:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:13:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:13:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:13:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:13:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:13:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:13:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:13:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:13:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:13:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:13:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:13:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:13:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:13:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:13:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:13:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:13:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:13:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:13:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:13:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:13:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:13:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:13:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:13:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:13:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:13:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:13:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:13:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:13:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:13:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:13:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:13:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:13:09 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:13:17 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:13:27 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:13:37 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:13:47 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:13:57 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:14:07 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:14:17 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:14:27 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:14:37 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:14:47 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:14:57 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:15:07 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:15:17 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:15:27 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:15:37 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:15:47 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:15:57 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:16:07 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:16:17 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:16:27 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.0.220:51431\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/10/07 21:16:27 ERROR Executor: Exit as unable to send heartbeats to driver more than 60 times\n",
      "----------------------------------------\n",
      "Exception happened during processing of request from ('127.0.0.1', 51458)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/socketserver.py\", line 316, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/usr/lib/python3.8/socketserver.py\", line 347, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/usr/lib/python3.8/socketserver.py\", line 360, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/usr/lib/python3.8/socketserver.py\", line 747, in __init__\n",
      "    self.handle()\n",
      "  File \"/home/skyeha/.local/lib/python3.8/site-packages/pyspark/accumulators.py\", line 295, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"/home/skyeha/.local/lib/python3.8/site-packages/pyspark/accumulators.py\", line 267, in poll\n",
      "    if self.rfile in r and func():\n",
      "  File \"/home/skyeha/.local/lib/python3.8/site-packages/pyspark/accumulators.py\", line 271, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "  File \"/home/skyeha/.local/lib/python3.8/site-packages/pyspark/serializers.py\", line 596, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "total_value_segments_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments = [\"Computers, Electronics, and Office Supplies\", \"Home, Garden, and Furnishings\", \"Books, Media, Arts, Crafts, and Hobbies\", \"Fashion, Personal Accessories, Health, and Beauty\"\n",
    "            , \"Vehicles, Repairs, and Miscellaneous Services\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------------+-----------------------------+-------------------------------------------+\n",
      "|merchant_abn|risk_adjusted_epv |name                         |segments                                   |\n",
      "+------------+------------------+-----------------------------+-------------------------------------------+\n",
      "|21439773999 |50237.87488272766 |Mauris Non Institute         |Computers, Electronics, and Office Supplies|\n",
      "|82368304209 |47340.66112303206 |Nec Incorporated             |Computers, Electronics, and Office Supplies|\n",
      "|35909341340 |40682.22831221837 |Arcu Sed Eu Incorporated     |Computers, Electronics, and Office Supplies|\n",
      "|45433476494 |36275.68139853707 |Adipiscing Elit Foundation   |Computers, Electronics, and Office Supplies|\n",
      "|58454491168 |35154.509483312075|Diam At Foundation           |Computers, Electronics, and Office Supplies|\n",
      "|94690988633 |34267.85544270964 |Eu Placerat LLC              |Computers, Electronics, and Office Supplies|\n",
      "|67400260923 |28740.143895221187|Eleifend PC                  |Computers, Electronics, and Office Supplies|\n",
      "|80518954462 |28358.23050269475 |Neque Sed Dictum Incorporated|Computers, Electronics, and Office Supplies|\n",
      "|57757792876 |26740.83898664496 |Pretium Et LLC               |Computers, Electronics, and Office Supplies|\n",
      "|34096466752 |26526.128306872553|Nullam Enim Ltd              |Computers, Electronics, and Office Supplies|\n",
      "+------------+------------------+-----------------------------+-------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seg1_ranking = complete_ranking.filter(F.col('segments') == segments[0])\n",
    "seg1_ranking = seg1_ranking.orderBy(\"risk_adjusted_epv\", ascending=False)\n",
    "seg1_ranking.write.parquet(f\"../data/curated/seg1_ranking.parquet\", mode='overwrite')\n",
    "seg1_ranking.show(10, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------------+------------------------------+-----------------------------+\n",
      "|merchant_abn|risk_adjusted_epv |name                          |segments                     |\n",
      "+------------+------------------+------------------------------+-----------------------------+\n",
      "|79827781481 |50753.42918974075 |Amet Risus Inc.               |Home, Garden, and Furnishings|\n",
      "|76767266140 |39744.37216363429 |Phasellus At Limited          |Home, Garden, and Furnishings|\n",
      "|43186523025 |37023.390424610785|Lorem Ipsum Sodales Industries|Home, Garden, and Furnishings|\n",
      "|49212265466 |32280.258727887383|Auctor Company                |Home, Garden, and Furnishings|\n",
      "|21772962346 |29226.73924604561 |Purus Gravida Sagittis Ltd    |Home, Garden, and Furnishings|\n",
      "|38090089066 |26982.619960897013|Interdum Feugiat Sed Inc.     |Home, Garden, and Furnishings|\n",
      "|42355028515 |26876.88514332147 |Eu Inc.                       |Home, Garden, and Furnishings|\n",
      "|76314317957 |26000.036184292283|Semper Corp.                  |Home, Garden, and Furnishings|\n",
      "|24852446429 |23186.20228093389 |Erat Vitae LLP                |Home, Garden, and Furnishings|\n",
      "|90543168331 |20781.929508536887|Phasellus Dapibus Incorporated|Home, Garden, and Furnishings|\n",
      "+------------+------------------+------------------------------+-----------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "seg2_ranking = complete_ranking.filter(F.col('segments') == segments[1])\n",
    "seg2_ranking = seg2_ranking.orderBy(\"risk_adjusted_epv\", ascending=False)\n",
    "seg2_ranking.write.parquet(f\"../data/curated/seg2_ranking.parquet\", mode='overwrite')\n",
    "seg2_ranking.show(10, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------------+-----------------------------+---------------------------------------+\n",
      "|merchant_abn|risk_adjusted_epv |name                         |segments                               |\n",
      "+------------+------------------+-----------------------------+---------------------------------------+\n",
      "|32361057556 |53912.79040771167 |Orci In Consequat Corporation|Books, Media, Arts, Crafts, and Hobbies|\n",
      "|45629217853 |51485.24888621164 |Lacus Consulting             |Books, Media, Arts, Crafts, and Hobbies|\n",
      "|64403598239 |49691.21355992612 |Lobortis Ultrices Company    |Books, Media, Arts, Crafts, and Hobbies|\n",
      "|94493496784 |44891.043232800184|Dictum Phasellus In Institute|Books, Media, Arts, Crafts, and Hobbies|\n",
      "|63123845164 |44701.43692027049 |Odio Phasellus Institute     |Books, Media, Arts, Crafts, and Hobbies|\n",
      "|72472909171 |40469.11957641558 |Nullam Consulting            |Books, Media, Arts, Crafts, and Hobbies|\n",
      "|79417999332 |40427.97266394555 |Phasellus At Company         |Books, Media, Arts, Crafts, and Hobbies|\n",
      "|40515428545 |40112.4793529307  |Elit Sed Consequat Associates|Books, Media, Arts, Crafts, and Hobbies|\n",
      "|27326652377 |38748.743017667766|Tellus Aenean Corporation    |Books, Media, Arts, Crafts, and Hobbies|\n",
      "|98973094975 |36338.63267471447 |Ornare Fusce Inc.            |Books, Media, Arts, Crafts, and Hobbies|\n",
      "+------------+------------------+-----------------------------+---------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "seg3_ranking = complete_ranking.filter(F.col('segments') == segments[2])\n",
    "seg3_ranking = seg3_ranking.orderBy(\"risk_adjusted_epv\", ascending=False)\n",
    "seg3_ranking.write.parquet(f\"../data/curated/seg3_ranking.parquet\", mode='overwrite')\n",
    "seg3_ranking.show(10, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------------+-----------------------------+-------------------------------------------------+\n",
      "|merchant_abn|risk_adjusted_epv |name                         |segments                                         |\n",
      "+------------+------------------+-----------------------------+-------------------------------------------------+\n",
      "|48534649627 |54713.17129337545 |Dignissim Maecenas Foundation|Fashion, Personal Accessories, Health, and Beauty|\n",
      "|86578477987 |54579.04496012397 |Leo In Consulting            |Fashion, Personal Accessories, Health, and Beauty|\n",
      "|49322182190 |45390.3585100905  |Gravida Mauris Incorporated  |Fashion, Personal Accessories, Health, and Beauty|\n",
      "|93558142492 |27957.937277723926|Dolor Quisque Inc.           |Fashion, Personal Accessories, Health, and Beauty|\n",
      "|11439466003 |24345.4354053516  |Blandit At LLC               |Fashion, Personal Accessories, Health, and Beauty|\n",
      "|95574756848 |21336.60624685837 |At Pede Inc.                 |Fashion, Personal Accessories, Health, and Beauty|\n",
      "|99976658299 |19586.089687544805|Sociosqu Corp.               |Fashion, Personal Accessories, Health, and Beauty|\n",
      "|62224020443 |18998.98769599394 |Hendrerit A Corporation      |Fashion, Personal Accessories, Health, and Beauty|\n",
      "|46804135891 |18890.05620563631 |Suspendisse Dui Corporation  |Fashion, Personal Accessories, Health, and Beauty|\n",
      "|81761494572 |17862.539408761997|Nulla Facilisis Institute    |Fashion, Personal Accessories, Health, and Beauty|\n",
      "+------------+------------------+-----------------------------+-------------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seg4_ranking = complete_ranking.filter(F.col('segments') == segments[3])\n",
    "seg4_ranking = seg4_ranking.orderBy(\"risk_adjusted_epv\", ascending=False)\n",
    "seg4_ranking.write.parquet(f\"../data/curated/seg4_ranking.parquet\", mode='overwrite')\n",
    "seg4_ranking.show(10, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 840:>                (0 + 3) / 3][Stage 843:>                (0 + 3) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------------+------------------------------+---------------------------------------------+\n",
      "|merchant_abn|risk_adjusted_epv |name                          |segments                                     |\n",
      "+------------+------------------+------------------------------+---------------------------------------------+\n",
      "|96680767841 |49906.659905709246|Ornare Limited                |Vehicles, Repairs, and Miscellaneous Services|\n",
      "|38700038932 |49510.49110209373 |Etiam Bibendum Industries     |Vehicles, Repairs, and Miscellaneous Services|\n",
      "|89726005175 |47880.09446935283 |Est Nunc Consulting           |Vehicles, Repairs, and Miscellaneous Services|\n",
      "|80551528183 |37912.869172420076|Ac Ipsum LLC                  |Vehicles, Repairs, and Miscellaneous Services|\n",
      "|49891706470 |36535.65054086117 |Non Vestibulum Industries     |Vehicles, Repairs, and Miscellaneous Services|\n",
      "|90568944804 |35928.5012315087  |Diam Eu Dolor LLC             |Vehicles, Repairs, and Miscellaneous Services|\n",
      "|13514558491 |35267.10118083442 |Magna Praesent PC             |Vehicles, Repairs, and Miscellaneous Services|\n",
      "|75454398468 |32470.586703261   |Tempus Non Lacinia Corporation|Vehicles, Repairs, and Miscellaneous Services|\n",
      "|68559320474 |29984.835543031975|Aliquam Auctor Associates     |Vehicles, Repairs, and Miscellaneous Services|\n",
      "|49549583265 |29787.8818223957  |Luctus Et Incorporated        |Vehicles, Repairs, and Miscellaneous Services|\n",
      "+------------+------------------+------------------------------+---------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "seg5_ranking = complete_ranking.filter(F.col('segments') == segments[4])\n",
    "seg5_ranking = seg5_ranking.orderBy(\"risk_adjusted_epv\", ascending=False)\n",
    "seg5_ranking.write.parquet(f\"../data/curated/seg5_ranking.parquet\", mode='overwrite')\n",
    "seg5_ranking.show(10, truncate = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
