{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.sys.path.append(\"../\")\n",
    "from scripts.preliminary_analysis import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "your 131072x1 screen size is bogus. expect trouble\n",
      "24/09/17 04:24:13 WARN Utils: Your hostname, DESKTOP-H0CEB6G resolves to a loopback address: 127.0.1.1; using 172.29.253.151 instead (on interface eth0)\n",
      "24/09/17 04:24:13 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/09/17 04:24:16 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "#  Create a Spark Session\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"Preliminary Data Analysis\")\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True)\n",
    "    .config(\"spark.sql.parquet.cacheMetadata\", \"true\")\n",
    "    .config(\"spark.sql.session.timeZone\", \"Etc/UTC\")\n",
    "    .config(\"spark.driver.memory\", \"4g\")\n",
    "    .config(\"spark.executor.memory\", \"2g\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../data/curated\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary Data Analysis\n",
    "\n",
    "In this notebook, we will conduct a preliminary data analysis on the data that we cleaned or are in the process of cleaning. The following statistics/visualisations will aid us in refining our cleaning pipeline, as well as help us to better understand our variables in preparation for analysis/modelling.\n",
    "\n",
    "## Merchants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "[PATH_NOT_FOUND] Path does not exist: file:/home/shipingkfc/project-2-group-buy-now-pay-later-industry-project-9/data/curated/merchant_fraud_prob.parquet.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Read merchant datasets in\u001b[39;00m\n\u001b[1;32m      2\u001b[0m merchant_info \u001b[38;5;241m=\u001b[39m spark\u001b[38;5;241m.\u001b[39mread\u001b[38;5;241m.\u001b[39mparquet(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/merchant_info.parquet\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m merchant_fp \u001b[38;5;241m=\u001b[39m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparquet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mpath\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/merchant_fraud_prob.parquet\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Summary Statistics\u001b[39;00m\n\u001b[1;32m      6\u001b[0m merchant_info\u001b[38;5;241m.\u001b[39mdescribe()\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyspark/sql/readwriter.py:544\u001b[0m, in \u001b[0;36mDataFrameReader.parquet\u001b[0;34m(self, *paths, **options)\u001b[0m\n\u001b[1;32m    533\u001b[0m int96RebaseMode \u001b[38;5;241m=\u001b[39m options\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mint96RebaseMode\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    534\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_opts(\n\u001b[1;32m    535\u001b[0m     mergeSchema\u001b[38;5;241m=\u001b[39mmergeSchema,\n\u001b[1;32m    536\u001b[0m     pathGlobFilter\u001b[38;5;241m=\u001b[39mpathGlobFilter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    541\u001b[0m     int96RebaseMode\u001b[38;5;241m=\u001b[39mint96RebaseMode,\n\u001b[1;32m    542\u001b[0m )\n\u001b[0;32m--> 544\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_df(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jreader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_to_seq\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_spark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpaths\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyspark/errors/exceptions/captured.py:185\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    181\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: [PATH_NOT_FOUND] Path does not exist: file:/home/shipingkfc/project-2-group-buy-now-pay-later-industry-project-9/data/curated/merchant_fraud_prob.parquet."
     ]
    }
   ],
   "source": [
    "# Read merchant datasets in\n",
    "merchant_info = spark.read.parquet(f\"{path}/merchant_info.parquet\")\n",
    "merchant_fp = spark.read.parquet(f\"{path}/merchant_fraud_prob.parquet\")\n",
    "\n",
    "# Summary Statistics\n",
    "merchant_info.describe().show()\n",
    "merchant_fp.describe().show()\n",
    "\n",
    "# Closer look at proportion of merchants with fraud prob data\n",
    "print(f'Total number of merchants: {merchant_info.select(\"merchant_abn\").distinct().count()}')\n",
    "print(f'Number of merchant with fraud probability in transactions: {merchant_fp.select(\"merchant_abn\").distinct().count()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the summary stats of the two merchant datasets, the notable columns are 'take_rate' and 'fraud_probability'. The other columns are not interpretable in terms of summary stats.\n",
    "\n",
    "Looking at the mins/maxs of both these columns, they appear to fall within a reasonable defined range. More analysis will be required to have a closer look at their distributions. (Skewed or balanced).\n",
    "\n",
    "We can see that there are only *61* merchants with a fraud probability out of *4026* which is only about *1%* This highlights the need to create a model to help us predict merchant fraud probability for imputation, which in turn will play a role in helping us determine which transactions are valid. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'merchant_fp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m functions \u001b[38;5;28;01mas\u001b[39;00m F\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Examine the frequency of fraud_prob for merchants and the average fraud prob accordingly\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mmerchant_fp\u001b[49m\u001b[38;5;241m.\u001b[39mgroupBy(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmerchant_abn\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39magg(\n\u001b[1;32m      5\u001b[0m     F\u001b[38;5;241m.\u001b[39mcount(F\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmerchant_abn\u001b[39m\u001b[38;5;124m\"\u001b[39m))\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_transaction_with_prob\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m      6\u001b[0m     F\u001b[38;5;241m.\u001b[39mavg(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfraud_probability\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mavg_prob\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'merchant_fp' is not defined"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Examine the frequency of fraud_prob for merchants and the average fraud prob accordingly\n",
    "merchant_fp.groupBy(\"merchant_abn\").agg(\n",
    "    F.count(F.col(\"merchant_abn\")).alias(\"num_transaction_with_prob\"),\n",
    "    F.avg(\"fraud_probability\").alias(\"avg_prob\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though the table only displays a small proportion of data, 20 rows, it is clear that some merchants have more than one transaction with fraud probability. This will be taken into consideration when merging datasets for later analysis/modelling. \n",
    "\n",
    "On the surface, there does not seem to be a correlation between number of transactions with fraud and the average fraud prob, but this may be further explored later on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consumer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+-----------------+\n",
      "|summary|fraud_probability|      consumer_id|\n",
      "+-------+-----------------+-----------------+\n",
      "|  count|            34864|            34864|\n",
      "|   mean|15.12009064415455|751897.9451870124|\n",
      "| stddev| 9.94608484957805|435809.7294939078|\n",
      "|    min|8.287143531552802|               30|\n",
      "|    max|99.24738020302328|          1499861|\n",
      "+-------+-----------------+-----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 31:==============>                                           (2 + 6) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------+-----------------+-----------+------+------------------+\n",
      "|summary|         name|      consumer_id|     gender| state|          postcode|\n",
      "+-------+-------------+-----------------+-----------+------+------------------+\n",
      "|  count|       499999|           499999|     499999|499999|            499999|\n",
      "|   mean|         NULL|750895.2123184246|       NULL|  NULL|4037.0854181708364|\n",
      "| stddev|         NULL|433100.4260141143|       NULL|  NULL|1791.0766391396735|\n",
      "|    min|Aaron Acevedo|                4|     Female|   ACT|               200|\n",
      "|    max|   Zoe Wright|          1499995|Undisclosed|    WA|              9999|\n",
      "+-------+-------------+-----------------+-----------+------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Read cleaned consumer data in\n",
    "consumer_fp = spark.read.parquet(f\"{path}/consumer_fraud_prob.parquet\")\n",
    "consumer_info = spark.read.parquet(f\"{path}/consumer_info.parquet\")\n",
    "\n",
    "# Summary statistics\n",
    "consumer_fp.describe().show()\n",
    "consumer_info.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the summary statistics above, the only column interpretable is 'fraud_probability'. \n",
    "\n",
    "We can see that fraud_probability is within a reasonable defined range, with a minimum of 8.28 and a maximum of about 99.24. Further discussion may be required to determine whether or not it would be beneficial to conduct outlier removal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary statistic of consumers fraud probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 35:===================================================>     (9 + 1) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|summary|        dollar_value|\n",
      "+-------+--------------------+\n",
      "|  count|            12561377|\n",
      "|   mean|  166.33982036554346|\n",
      "| stddev|   520.3624254515656|\n",
      "|    min|9.756658099412162E-8|\n",
      "|    max|  105193.88578925544|\n",
      "+-------+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Read in transactions dataset\n",
    "transactions = spark.read.parquet(f\"{path}/transactions.parquet\")\n",
    "\n",
    "# Summary Statistics\n",
    "transactions.select(F.col(\"dollar_value\")).describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the summary statistics observed, we can see that dollar value has a minimum of $0.00000009.\n",
    "\n",
    "This is significantly lower than even 1 cent. Therefore, it would appear to be appropriate to consider rows which such value as invalid. \n",
    "\n",
    "However, as values like these could be indicators of fraudulent transactions, we should consider retaining these rows to help us later on with predicting fraud. We will revisit this after joining our datasets and understand the relationships between variables better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\navg_revenue_level = merchant_info.groupBy(\"revenue_level\").agg(\\n    F.count(F.col(\"commission_amount\")).alias(\"num_merchant\"),\\n    F.sum(F.col(\"total_orders\")).alias(\"total_orders\"),\\n    F.round(F.avg(F.col(\"commission_amount\")),2).alias(\"avg_commission_amount\"),\\n    F.round(F.sum(F.col(\"commission_amount\")),2).alias(\"total_commission_amount\"),\\n)\\n# avg_revenue_level = avg_revenue_level.withColumn(\"total_commission_amount\", F.format_number(\"total_commission_amount\", 2))\\navg_revenue_level.withColumns(\\n    {\"avg_commission_amount\": F.format_number(\"avg_commission_amount\",2),\\n    \"total_commission_amount\": F.format_number(\"total_commission_amount\",2),}\\n)\\n\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "avg_revenue_level = merchant_info.groupBy(\"revenue_level\").agg(\n",
    "    F.count(F.col(\"commission_amount\")).alias(\"num_merchant\"),\n",
    "    F.sum(F.col(\"total_orders\")).alias(\"total_orders\"),\n",
    "    F.round(F.avg(F.col(\"commission_amount\")),2).alias(\"avg_commission_amount\"),\n",
    "    F.round(F.sum(F.col(\"commission_amount\")),2).alias(\"total_commission_amount\"),\n",
    ")\n",
    "# avg_revenue_level = avg_revenue_level.withColumn(\"total_commission_amount\", F.format_number(\"total_commission_amount\", 2))\n",
    "avg_revenue_level.withColumns(\n",
    "    {\"avg_commission_amount\": F.format_number(\"avg_commission_amount\",2),\n",
    "    \"total_commission_amount\": F.format_number(\"total_commission_amount\",2),}\n",
    ")\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'transaction_records_final' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Convert columns to Pandas for plotting\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m df_pandas \u001b[38;5;241m=\u001b[39m \u001b[43mtransaction_records_final\u001b[49m\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdollar_value\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmerchant_fraud_probability\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconsumer_fraud_probability\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mtoPandas()\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Plot the distribution for dollar_value with better scaling\u001b[39;00m\n\u001b[1;32m      7\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'transaction_records_final' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Convert columns to Pandas for plotting\n",
    "df_pandas = transaction_records_final.select(\"dollar_value\", \"merchant_fraud_probability\", \"consumer_fraud_probability\").toPandas()\n",
    "\n",
    "# Plot the distribution for dollar_value with better scaling\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(df_pandas['dollar_value'], bins=50, color='blue', alpha=0.7, log=True)  # Apply log scale to y-axis\n",
    "plt.title(\"Dollar Value Distribution (Before Removing Outliers)\")\n",
    "plt.xlabel(\"Dollar Value\")\n",
    "plt.ylabel(\"Frequency (log scale)\")\n",
    "plt.xlim([0, 100000])  # Adjust x-axis limits\n",
    "plt.show()\n",
    "\n",
    "# Plot the distribution for fraud_probability (merchant) with better scaling\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(df_pandas['merchant_fraud_probability'], bins=50, color='green', alpha=0.7, log=True)  # Apply log scale to y-axis\n",
    "plt.title(\"Merchant Fraud Probability Distribution (Before Removing Outliers)\")\n",
    "plt.xlabel(\"Merchant Fraud Probability\")\n",
    "plt.ylabel(\"Frequency (log scale)\")\n",
    "plt.xlim([20, 70])  # Adjust x-axis limits\n",
    "plt.show()\n",
    "\n",
    "# Plot the distribution for fraud_probability (consumer) with better scaling\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(df_pandas['consumer_fraud_probability'], bins=50, color='red', alpha=0.7, log=True)  # Apply log scale to y-axis\n",
    "plt.title(\"Consumer Fraud Probability Distribution (Before Removing Outliers)\")\n",
    "plt.xlabel(\"Consumer Fraud Probability\")\n",
    "plt.ylabel(\"Frequency (log scale)\")\n",
    "plt.xlim([0, 100])  # Adjust x-axis limits\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename fraud_probability in the merchant fraud dataset to 'merchant_fraud_probability'\n",
    "merchant_fp = merchant_fp.withColumnRenamed(\"fraud_probability\", \"merchant_fraud_probability\")\n",
    "\n",
    "# Rename fraud_probability in the consumer fraud dataset to 'consumer_fraud_probability'\n",
    "consumer_fp = consumer_fp.withColumnRenamed(\"fraud_probability\", \"consumer_fraud_probability\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset:\n",
      "The dataset count is  12561377\n",
      "\n",
      "\n",
      "After consumer_fp join:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset count is  12561589\n",
      "+-----------+--------------+------------+------------------+--------------------+--------------------------+\n",
      "|consumer_id|order_datetime|merchant_abn|      dollar_value|            order_id|consumer_fraud_probability|\n",
      "+-----------+--------------+------------+------------------+--------------------+--------------------------+\n",
      "|    1059280|    2021-11-26| 79417999332|136.06570809815838|23acbb7b-cf98-458...|                      NULL|\n",
      "|    1195503|    2021-11-26| 46451548968| 72.61581642788431|76bab304-fa2d-400...|                      NULL|\n",
      "|     986886|    2021-11-26| 89518629617|3.0783487174439297|a2ae446a-2959-41c...|                      NULL|\n",
      "|    1195503|    2021-11-26| 49167531725| 51.58228625503599|7080c274-17f7-4cc...|                      NULL|\n",
      "|     986886|    2021-11-26| 31101120643|25.228114942417797|8e301c0f-06ab-45c...|                      NULL|\n",
      "+-----------+--------------+------------+------------------+--------------------+--------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+----------------------------+--------------------------+--------------------------+----------------------+----------------------------------------+\n",
      "|consumer_id_missing_count|order_datetime_missing_count|merchant_abn_missing_count|dollar_value_missing_count|order_id_missing_count|consumer_fraud_probability_missing_count|\n",
      "+-------------------------+----------------------------+--------------------------+--------------------------+----------------------+----------------------------------------+\n",
      "|                        0|                           0|                         0|                         0|                     0|                                12481029|\n",
      "+-------------------------+----------------------------+--------------------------+--------------------------+----------------------+----------------------------------------+\n",
      "\n",
      "After merchant_fp join:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset count is  12561589\n",
      "+------------+--------------+-----------+------------------+--------------------+--------------------------+--------------------------+\n",
      "|merchant_abn|order_datetime|consumer_id|      dollar_value|            order_id|consumer_fraud_probability|merchant_fraud_probability|\n",
      "+------------+--------------+-----------+------------------+--------------------+--------------------------+--------------------------+\n",
      "| 79417999332|    2021-11-26|    1059280|136.06570809815838|23acbb7b-cf98-458...|                      NULL|                      NULL|\n",
      "| 46451548968|    2021-11-26|    1195503| 72.61581642788431|76bab304-fa2d-400...|                      NULL|                      NULL|\n",
      "| 89518629617|    2021-11-26|     986886|3.0783487174439297|a2ae446a-2959-41c...|                      NULL|                      NULL|\n",
      "| 49167531725|    2021-11-26|    1195503| 51.58228625503599|7080c274-17f7-4cc...|                      NULL|                      NULL|\n",
      "| 31101120643|    2021-11-26|     986886|25.228114942417797|8e301c0f-06ab-45c...|                      NULL|                      NULL|\n",
      "+------------+--------------+-----------+------------------+--------------------+--------------------------+--------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------+----------------------------+-------------------------+--------------------------+----------------------+----------------------------------------+----------------------------------------+\n",
      "|merchant_abn_missing_count|order_datetime_missing_count|consumer_id_missing_count|dollar_value_missing_count|order_id_missing_count|consumer_fraud_probability_missing_count|merchant_fraud_probability_missing_count|\n",
      "+--------------------------+----------------------------+-------------------------+--------------------------+----------------------+----------------------------------------+----------------------------------------+\n",
      "|                         0|                           0|                        0|                         0|                     0|                                12481029|                                12557495|\n",
      "+--------------------------+----------------------------+-------------------------+--------------------------+----------------------+----------------------------------------+----------------------------------------+\n",
      "\n",
      "After merchant_info join:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset count is  12047496\n",
      "+------------+--------------+-----------+------------------+--------------------+--------------------------+--------------------------+--------------------+--------------------+-------------+---------+\n",
      "|merchant_abn|order_datetime|consumer_id|      dollar_value|            order_id|consumer_fraud_probability|merchant_fraud_probability|                name|            category|revenue_level|take_rate|\n",
      "+------------+--------------+-----------+------------------+--------------------+--------------------------+--------------------------+--------------------+--------------------+-------------+---------+\n",
      "| 79417999332|    2021-11-26|    1059280|136.06570809815838|23acbb7b-cf98-458...|                      NULL|                      NULL|Phasellus At Company|gift, card, novel...|            b|     4.95|\n",
      "| 46451548968|    2021-11-26|    1195503| 72.61581642788431|76bab304-fa2d-400...|                      NULL|                      NULL|Tempus Eu Ligula ...|health and beauty...|            a|     6.04|\n",
      "| 89518629617|    2021-11-26|     986886|3.0783487174439297|a2ae446a-2959-41c...|                      NULL|                      NULL|Vulputate Velit E...|tent  and awning ...|            c|     3.09|\n",
      "| 49167531725|    2021-11-26|    1195503| 51.58228625503599|7080c274-17f7-4cc...|                      NULL|                      NULL|     Felis Institute|digital goods: bo...|            a|     6.42|\n",
      "| 31101120643|    2021-11-26|     986886|25.228114942417797|8e301c0f-06ab-45c...|                      NULL|                      NULL|Commodo Hendrerit...|cable, satellite,...|            a|     6.37|\n",
      "+------------+--------------+-----------+------------------+--------------------+--------------------------+--------------------------+--------------------+--------------------+-------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 212:==================================================>     (9 + 1) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------+----------------------------+-------------------------+--------------------------+----------------------+----------------------------------------+----------------------------------------+------------------+----------------------+---------------------------+-----------------------+\n",
      "|merchant_abn_missing_count|order_datetime_missing_count|consumer_id_missing_count|dollar_value_missing_count|order_id_missing_count|consumer_fraud_probability_missing_count|merchant_fraud_probability_missing_count|name_missing_count|category_missing_count|revenue_level_missing_count|take_rate_missing_count|\n",
      "+--------------------------+----------------------------+-------------------------+--------------------------+----------------------+----------------------------------------+----------------------------------------+------------------+----------------------+---------------------------+-----------------------+\n",
      "|                         0|                           0|                        0|                         0|                     0|                                11975680|                                12043468|                 0|                     0|                          0|                      0|\n",
      "+--------------------------+----------------------------+-------------------------+--------------------------+----------------------+----------------------------------------+----------------------------------------+------------------+----------------------+---------------------------+-----------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Check initial dataset size\n",
    "print(\"Original dataset:\")\n",
    "get_dataset_count(transactions)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Join transaction_records with consumer fraud data\n",
    "transaction_records_with_consumer_fraud = transactions.join(\n",
    "    consumer_fp, \n",
    "    on=[\"consumer_id\", \"order_datetime\"], \n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "print(\"After consumer_fp join:\")\n",
    "\n",
    "# See how the dataset size changes along the way\n",
    "get_dataset_count(transaction_records_with_consumer_fraud)\n",
    "\n",
    "# Preview\n",
    "transaction_records_with_consumer_fraud.show(5)\n",
    "\n",
    "# Check if the join led to any missing values.\n",
    "calculate_missing_values(transaction_records_with_consumer_fraud)\n",
    "\n",
    "# Join transaction records with merchant fraud data\n",
    "transaction_records_with_fraud = transaction_records_with_consumer_fraud.join(\n",
    "    merchant_fp, \n",
    "    on=[\"merchant_abn\", \"order_datetime\"], \n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "print(\"After merchant_fp join:\")\n",
    "\n",
    "# See how the dataset size changes along the way\n",
    "get_dataset_count(transaction_records_with_fraud)\n",
    "\n",
    "# Preview\n",
    "transaction_records_with_fraud.show(5)\n",
    "\n",
    "# Check if the join led to any missing values.\n",
    "calculate_missing_values(transaction_records_with_fraud)\n",
    "\n",
    "# Join transaction records with merchant info\n",
    "transaction_records_final = transaction_records_with_fraud.join(\n",
    "    merchant_info, \n",
    "    on=\"merchant_abn\", \n",
    "    how=\"inner\"\n",
    ")\n",
    "\n",
    "print(\"After merchant_info join:\")\n",
    "\n",
    "# See how the dataset size changes along the way\n",
    "get_dataset_count(transaction_records_final)\n",
    "\n",
    "# Preview\n",
    "transaction_records_final.show(5)\n",
    "\n",
    "# See how the dataset size changes along the way\n",
    "# Check if the join led to any missing values.\n",
    "calculate_missing_values(transaction_records_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 74:===================================================>     (9 + 1) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------------+-------------------+------------+\n",
      "|merchant_abn|    total_revenue|average_order_value|total_orders|\n",
      "+------------+-----------------+-------------------+------------+\n",
      "| 39649557865| 8713454.72918194|  449.1471509887598|       19400|\n",
      "| 31334588839|  8710106.7140746|  6413.922469863476|        1358|\n",
      "| 27093785141|8695204.207713192|  377.1668347233969|       23054|\n",
      "| 96680767841|8679874.166938104| 315.16191013173466|       27541|\n",
      "| 79827781481|8657277.096810075| 2036.5271928511113|        4251|\n",
      "| 32709545238|8600648.766611947|  751.2139721034105|       11449|\n",
      "| 82368304209|8559519.374213614| 1865.6319473002645|        4588|\n",
      "| 50315283629|8513752.395678477|  322.3685117636682|       26410|\n",
      "| 90568944804|8510417.447779242|  898.9561051842444|        9467|\n",
      "| 38700038932|8482176.655705512| 1337.6717640286251|        6341|\n",
      "+------------+-----------------+-------------------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Revenue analysis\n",
    "merchant_performance = transaction_records_final.groupBy(\"merchant_abn\").agg(\n",
    "    F.sum(\"dollar_value\").alias(\"total_revenue\"),\n",
    "    F.avg(\"dollar_value\").alias(\"average_order_value\"),\n",
    "    F.count(\"dollar_value\").alias(\"total_orders\")\n",
    ")\n",
    "\n",
    "# Rank merchants by total revenue in descending order\n",
    "merchant_performance = merchant_performance.orderBy(F.col(\"total_revenue\").desc())\n",
    "merchant_performance.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 80:===================================================>     (9 + 1) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------------------+-----------------------+------------------+-------------------+------------+\n",
      "|merchant_abn|merchant_avg_fraud_prob|consumer_avg_fraud_prob|     total_revenue|average_order_value|total_orders|\n",
      "+------------+-----------------------+-----------------------+------------------+-------------------+------------+\n",
      "| 35575706403|      91.09606847149965|     34.776805865701846| 806977.6688917434| 11867.318660172697|          68|\n",
      "| 97884414539|      89.79919971536573|      32.40204688123495| 668322.1558769114| 11724.950103103709|          57|\n",
      "| 14530561097|      80.80054474543395|      31.83820084048247|1900373.3585338441| 11379.481188825413|         167|\n",
      "| 18737319630|      72.73069736562613|      9.716308521768319| 39719.82955985059|  201.6235003038101|         197|\n",
      "| 85482742429|      70.88131110541714|     13.662992056430278| 34194.42789673934|  71.53646003501954|         478|\n",
      "| 78080443264|      69.09531723361212|     12.295498809402012| 19336.11299420864| 20.247238737391246|         955|\n",
      "| 76968105359|       68.2784363254391|       12.3505503361881|191633.82993886337|  293.9169170841463|         652|\n",
      "| 80089686333|       67.5058112247036|      18.21383768928501| 82881.52553626813|    87.151972172732|         951|\n",
      "| 79100970961|       67.1177397510102|      35.04800856081171|1105901.4104871452| 16505.991201300676|          67|\n",
      "| 93292821052|      66.58725735032715|                   NULL|114082.48981705836| 262.25859728059396|         435|\n",
      "+------------+-----------------------+-----------------------+------------------+-------------------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Risk analysis\n",
    "merchant_performance_risk = transaction_records_final.groupBy(\"merchant_abn\").agg(\n",
    "    F.avg(\"merchant_fraud_probability\").alias(\"merchant_avg_fraud_prob\"),\n",
    "    F.avg(\"consumer_fraud_probability\").alias(\"consumer_avg_fraud_prob\"),\n",
    "    F.sum(\"dollar_value\").alias(\"total_revenue\"),\n",
    "    F.avg(\"dollar_value\").alias(\"average_order_value\"),\n",
    "    F.count(\"dollar_value\").alias(\"total_orders\")\n",
    ")\n",
    "\n",
    "# Rank merchants by fraud probability in descending order\n",
    "merchant_performance_risk = merchant_performance_risk.orderBy(F.col(\"merchant_avg_fraud_prob\").desc())\n",
    "merchant_performance_risk.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 86:===================================================>     (9 + 1) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------------+-----------------+-------------------+------------+-----------------------+-----------------------+\n",
      "|merchant_abn| total_net_revenue|    total_revenue|average_order_value|total_orders|merchant_avg_fraud_prob|consumer_avg_fraud_prob|\n",
      "+------------+------------------+-----------------+-------------------+------------+-----------------------+-----------------------+\n",
      "| 79827781481| 590426.2980024472|8657277.096810075| 2036.5271928511113|        4251|     29.694380203418124|      12.77383070226627|\n",
      "| 48534649627| 552231.2486106261|8316735.671846778| 141.71825290699118|       58685|     28.576898179225296|     14.902087132634948|\n",
      "| 32361057556| 551286.8853157675|8340194.936698442| 109.94917852084164|       75855|                   NULL|     15.816853351282546|\n",
      "| 86578477987| 542906.0687302663|8443329.218200121|  34.98505938982652|      241341|                   NULL|     15.121133124846919|\n",
      "| 38700038932| 535225.3469750177|8482176.655705512| 1337.6717640286251|        6341|                   NULL|     11.164228026866118|\n",
      "| 45629217853|519102.37032040104|7436996.709461323| 36.847095679921736|      201834|                   NULL|      15.42903978993496|\n",
      "| 96680767841|512980.56326604146|8679874.166938104| 315.16191013173466|       27541|     29.555244690424946|     14.681584730926248|\n",
      "| 21439773999| 508624.7782137687|8338111.118258502|  78.12560194007611|      106727|     28.504479048104358|     15.102006498508809|\n",
      "| 63123845164| 498873.6049547038|7570160.924957567|   751.380736968493|       10075|                   NULL|     11.570886106200385|\n",
      "| 64403598239| 494880.5164593867| 7842797.40823117|  78.11862432996504|      100396|                   NULL|     14.901582742852447|\n",
      "+------------+------------------+-----------------+-------------------+------------+-----------------------+-----------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Profitability analysis\n",
    "# Calculate net revenue at the transaction level before aggregation\n",
    "transaction_records_final = transaction_records_final.withColumn(\n",
    "    \"net_revenue\", F.col(\"dollar_value\") * F.col(\"take_rate\")/100\n",
    ")\n",
    "\n",
    "# Aggregate net_revenue at the merchant level\n",
    "merchant_profitability = transaction_records_final.groupBy(\"merchant_abn\").agg(\n",
    "    F.sum(\"net_revenue\").alias(\"total_net_revenue\"),\n",
    "    F.sum(\"dollar_value\").alias(\"total_revenue\"),\n",
    "    F.avg(\"dollar_value\").alias(\"average_order_value\"),\n",
    "    F.count(\"dollar_value\").alias(\"total_orders\"),\n",
    "    F.avg(\"merchant_fraud_probability\").alias(\"merchant_avg_fraud_prob\"),\n",
    "    F.avg(\"consumer_fraud_probability\").alias(\"consumer_avg_fraud_prob\")\n",
    ")\n",
    "\n",
    "# Rank merchants by profitability in descending order\n",
    "merchant_profitability.orderBy(F.col(\"total_net_revenue\").desc()).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>revenue_level</th><th>avg(take_rate)</th></tr>\n",
       "<tr><td>e</td><td>0.3147169811320755</td></tr>\n",
       "<tr><td>d</td><td>0.9912244897959185</td></tr>\n",
       "<tr><td>c</td><td>2.2512039045553167</td></tr>\n",
       "<tr><td>b</td><td>4.094056254626199</td></tr>\n",
       "<tr><td>a</td><td>6.232297128589269</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-------------+------------------+\n",
       "|revenue_level|    avg(take_rate)|\n",
       "+-------------+------------------+\n",
       "|            e|0.3147169811320755|\n",
       "|            d|0.9912244897959185|\n",
       "|            c|2.2512039045553167|\n",
       "|            b| 4.094056254626199|\n",
       "|            a| 6.232297128589269|\n",
       "+-------------+------------------+"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merchant_info.groupBy(F.col(\"revenue_level\")).agg(F.avg(F.col(\"take_rate\"))) # average commission rate of each revenue level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_revenue_level = merchant_profitability.groupBy('revenue_level').sum('net_revenue') #sum up the net_revenue of BNPL firm for each level\n",
    "net_revenue_level\n",
    "#Data shows that make the most net_revenue from small "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the occurrences of each revenue level\n",
    "merchant_profitability.groupBy('revenue_level').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of merchants with a fraud probability\n",
    "fraudulent_merchants_count = merchant_profitability.filter(col(\"merchant_avg_fraud_prob\").isNotNull()).select(\"merchant_abn\").distinct().count()\n",
    "\n",
    "fraudulent_merchants_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Compute the average fraud probability for each revenue level\n",
    "average_fraud_by_revenue_level = merchant_profitability.groupBy(F.col(\"revenue_level\")).agg(F.avg(F.col(\"merchant_avg_fraud_prob\")).alias(\"merchant_avg_fraud_prob\"))\n",
    "\n",
    "# Show the results\n",
    "average_fraud_by_revenue_level.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the total number of orders for each revenue level\n",
    "total_orders_by_revenue_level = merchant_profitability.groupBy(F.col(\"revenue_level\")) \\\n",
    "    .agg(F.sum(F.col(\"total_orders\")).alias(\"total_orders\"))\n",
    "\n",
    "# Show the results\n",
    "total_orders_by_revenue_level.show()\n",
    "\n",
    "joined_df = net_revenue_level.join(\n",
    "    total_orders_by_revenue_level,\n",
    "    on=\"revenue_level\",\n",
    "    how=\"inner\"\n",
    ")\n",
    "joined_df = joined_df.withColumn(\"total_orders\", F.col(\"total_orders\").cast(DoubleType()))\n",
    "\n",
    "# Compute the average order value\n",
    "average_order_value = joined_df.withColumn(\n",
    "    \"avg_order_value\",\n",
    "    F.col(\"sum(net_revenue)\")/ F.col(\"total_orders\")\n",
    ")\n",
    "\n",
    "average_order_value\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
